<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|EB Garamond:300,300italic,400,400italic,700,700italic|Source Code Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"wadmes.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"buttons","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"./public/search.xml"};
  </script>

  <meta name="description" content="人生注定是一个人的旅行，但就算孤独也要做一直前行的人啊">
<meta property="og:type" content="website">
<meta property="og:title" content="NEWAY">
<meta property="og:url" content="http://wadmes.github.io/page/5/index.html">
<meta property="og:site_name" content="NEWAY">
<meta property="og:description" content="人生注定是一个人的旅行，但就算孤独也要做一直前行的人啊">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Li Wei">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://wadmes.github.io/page/5/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>NEWAY - 愿识乾坤大，仍怜草木青</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">NEWAY</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">愿识乾坤大，仍怜草木青</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-reading-notes">

    <a href="/notes" rel="section"><i class="fas fa-book-reader fa-fw"></i>Reading notes</a>

  </li>
        <li class="menu-item menu-item-about-me">

    <a href="/about" rel="section"><i class="fas fa-user fa-fw"></i>About me</a>

  </li>
        <li class="menu-item menu-item-official-about-me">

    <a href="/cv" rel="section"><i class="fas fa-user-secret fa-fw"></i>Official About me</a>

  </li>
        <li class="menu-item menu-item-resume">

    <a href="/cv/cv_liwei/cv.pdf" rel="section"><i class="fas fa-file fa-fw"></i>Resume</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://wadmes.github.io/2021/04/02/Study-notes-matrics-for-engineering/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/liwei3.jpg">
      <meta itemprop="name" content="Li Wei">
      <meta itemprop="description" content="人生注定是一个人的旅行，但就算孤独也要做一直前行的人啊">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NEWAY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/02/Study-notes-matrics-for-engineering/" class="post-title-link" itemprop="url">Study notes: matrics for engineering</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-02 13:35:44" itemprop="dateCreated datePublished" datetime="2021-04-02T13:35:44-04:00">2021-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-05-18 02:11:20" itemprop="dateModified" datetime="2021-05-18T02:11:20-04:00">2021-05-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/study/" itemprop="url" rel="index"><span itemprop="name">study</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2021/04/02/Study-notes-matrics-for-engineering/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/04/02/Study-notes-matrics-for-engineering/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Some-mathematical-English"><a href="#Some-mathematical-English" class="headerlink" title="Some mathematical English"></a>Some mathematical English</h1><p>$A$ : <em>capital</em> A</p>
<p>$A^T$: capital A <em>superscript</em>(下标：subscript) capital T</p>
<p>$A^{-1}$: capital A <em>to</em> the minus one </p>
<p>$1&#x2F;2$:  one over two</p>
<h1 id="Some-forgotten-terms"><a href="#Some-forgotten-terms" class="headerlink" title="Some forgotten terms"></a>Some forgotten terms</h1><p><strong>Banded matrix</strong>: like a diagonal matrix, but it has also elements above the main diagonal and below the main diagonal.</p>
<p><strong>Triangular matrix</strong>: only has elements above (upper) or below (lower) the main diagonal.</p>
<p><strong>Skew-symmetric matrix</strong>: $A^T&#x3D;-A$ (so that the diagnoal element is zero)</p>
<p><strong>Orthonormal vectors</strong>: the two vectors $u,v$ (usually, when we say a vector, its dimension is n by 1, a column vector), are both orthogonal $u^Tv &#x3D; 0$ and normalized (||u|| &#x3D; ||v|| &#x3D; 1)</p>
<p><strong>orthogonal matrix</strong>:</p>
<ul>
<li>$Q^{-1}&#x3D; Q^T$</li>
<li>$QQ^T &#x3D; I$</li>
<li>In the multiplication above, if selected rows are the same, results are 1 (diagonal element), otherwise, 0</li>
<li>That is, the row&#x2F;column vectors are <strong>othernormal vectors</strong></li>
<li>$(Q X)^T(QX) &#x3D; ||QX||^2 &#x3D; X^TQ^TQX &#x3D; X^TX &#x3D; ||X||^2$: an orthogonal matrix <strong>preserves the norms and lengths.</strong></li>
</ul>
<h1 id="LU-decomposition"><a href="#LU-decomposition" class="headerlink" title="LU decomposition"></a>LU decomposition</h1><p><strong>Elementary matrix</strong>: the identity matrix with one of the zeros replaced by a number</p>
<blockquote>
<p>Consider matrix multiplication R &#x3D; M$\times$A:</p>
<p>$R_1$ (the first row of R) is calculated by the combination sum:  $m_{11}\times A_1 + m_{12}\times A_2 +…$</p>
</blockquote>
<p><strong>Inverse of elementary matrix</strong>: swap the sign of non-zero element (Think $MM^{-1}A &#x3D; A$)</p>
<p>Eg: </p>
<p>$$M &#x3D; \begin{bmatrix}<br>1 &amp; 0 &amp; 0 \<br>0 &amp; 1 &amp; 0 \ -1&amp; 0 &amp; 1 \end{bmatrix}$$</p>
<p>$$M^{-1} &#x3D; \begin{bmatrix}<br>1 &amp; 0 &amp; 0 \<br>0 &amp; 1 &amp; 0 \ 1&amp; 0 &amp; 1 \end{bmatrix}$$</p>
<p>$$M &#x3D; \begin{bmatrix}<br>1 &amp; 0 &amp; 0 \<br>0 &amp; 1 &amp; 0 \ -1&amp; 0 &amp; 1 \end{bmatrix}$$</p>
<p><strong>LU decomposition</strong>: A &#x3D; LU, L is a lower triangular matrix and U is a upper triangular matrix.</p>
<p>Then, when we try to solve Ax &#x3D; b, we can actually solve (LU)x &#x3D; b cause y &#x3D; Ux, Ly &#x3D; b are easier to compute compared with Ax&#x3D; b. (Note L,U are triangular matrices).</p>
<blockquote>
<p>Note: it is NOT computational-friendly by LU decomposition if we only calculate Ax&#x3D;b once. However, if there are multiple b, we can decompose A one time, and benefit from the effecient computation by triangular matrix.</p>
</blockquote>
<h1 id="Vector-Space"><a href="#Vector-Space" class="headerlink" title="Vector Space"></a>Vector Space</h1><p>vector space &#x3D; set of vectors (in this course, column matrices) + set of scalars (real numbers)</p>
<p>should be <strong>closed</strong> under vector addition and scalar multiplication</p>
<h2 id="Linear-Independence"><a href="#Linear-Independence" class="headerlink" title="Linear Independence"></a>Linear Independence</h2><p>The set of vectors ${u_1,…,u_n}$ are linearly independent if $c_1u_1 + … +c_nu_n &#x3D; 0$ has only solution $c_1&#x3D;c_2&#x3D;…&#x3D;c_n$.</p>
<blockquote>
<p>meaning: no vector in the set can be written as a linear combination of other vectors.</p>
</blockquote>
<p><strong>span</strong>: we say a set of vector ${u_1,…,u_n}$ <strong>span</strong> a vector space only consisting of all linear combinations of  ${u_1,…,u_n}$.</p>
<p><strong>basis</strong> of a vector space is a set of minumum # of vectors that span the space.</p>
<p>The munumum # above is <strong>dimension</strong>.</p>
<h2 id="Null-Space"><a href="#Null-Space" class="headerlink" title="Null Space"></a>Null Space</h2><p>Null(A) is a vector space of all column vectors x s.t. Ax &#x3D; 0.</p>
<p> That is, the dot product between row vector and the null vector (vector in the null space) is zero.</p>
<p>Thereofore, row space is orthogonal with null space.</p>
<p>Therefore, dim(Row(A)) + dim(Null(A)) &#x3D; n (why?)</p>
<blockquote>
<p>Left Null Space: $x^TA &#x3D; 0$</p>
</blockquote>
<h2 id="Column-Space"><a href="#Column-Space" class="headerlink" title="Column Space"></a>Column Space</h2><p>$$Mx &#x3D; \begin{bmatrix}<br>a &amp; b  \<br>c &amp;d  \end{bmatrix} \begin{bmatrix}<br>x_1   \<br>x_2   \end{bmatrix} &#x3D; x_1\begin{bmatrix}<br>a   \<br>c   \end{bmatrix}+x_2\begin{bmatrix}<br>b   \<br>d   \end{bmatrix}$$</p>
<blockquote>
<p>Consider row space: $$x^TM &#x3D; \begin{bmatrix}<br>x_1  &amp;<br>x_2   \end{bmatrix}\begin{bmatrix}<br>a &amp; b  \<br>c &amp;d  \end{bmatrix}  &#x3D; x_1\begin{bmatrix}<br>a  &amp;<br>b   \end{bmatrix}+x_2\begin{bmatrix}<br>c   &amp;<br>d   \end{bmatrix}$$</p>
<p>$x^TM$ gives you a vector that is in the row space of M</p>
</blockquote>
<p>Above: linear combination of columns of the matrix (in the column space); <strong>Mx gives you a vector that is in the column space of M.</strong></p>
<p><strong>Dimension</strong> of column space eqauls to the dimension of row space, i.e., dim(Col(A)) &#x3D; dim(Col(A$^T$)), where the dimension is called <strong>rank</strong> of A.&#x3D; number of linearly independent columns </p>
<h2 id="Relationships-of-Null-Space-Column-Space-and-Row-space"><a href="#Relationships-of-Null-Space-Column-Space-and-Row-space" class="headerlink" title="Relationships of Null Space, Column Space, and Row space."></a>Relationships of Null Space, Column Space, and Row space.</h2><ol>
<li>The <strong>column space</strong> of M can be represented by the space spaned by $Mx$. for any x.</li>
<li>Similarly, the <strong>row space</strong> of M can be represented by the space spaned by $x^TM$ for any x.</li>
<li>Dim(Col(A)) &#x3D; dim(Row(A)) &#x3D; rank</li>
<li>Dim(Null(A)) &#x3D; n - r</li>
<li>Dim(Null($A^T$) &#x3D; m - r</li>
</ol>
<h2 id="Orthogonal-Projections"><a href="#Orthogonal-Projections" class="headerlink" title="Orthogonal Projections"></a>Orthogonal Projections</h2><p>Project vector down into a subspace. The projected vector is the vector in the subspace that is closest to the original vector.</p>
<h2 id="One-example-Solution-of-the-Least-Squares-Problem"><a href="#One-example-Solution-of-the-Least-Squares-Problem" class="headerlink" title="One example: Solution of the Least-Squares Problem"></a>One example: Solution of the Least-Squares Problem</h2><p>Ax &#x3D; b (x is the target ), $A\in \R^{m\times n}, m&gt;n$</p>
<p>b is the y-axis data point value, A is a matrix related to x-axis data point value. The equation Ax&#x3D;b assumes that the line (represented in x) can go through all points, which is impossible.</p>
<p>Therefore, this is considered as over-determined.</p>
<p>Remeber that Ax gives you a vector that is in the column space of A. If Ax&#x3D;b is over-determined, that means b is not in the column space of A since there is no solution.</p>
<p><strong>But to find the best solution, what we can do is to project b into the column space of A.</strong></p>
<p>So, we cannot solve Ax&#x3D;b, instead, we solve Ax&#x3D; $b_{projCol(A)}$.</p>
<p>write $b &#x3D; b_{projCol(A)}$ + $b - b_{projCol(A)}$</p>
<p>Consdier the term $b - b_{projCol(A)}$ is orthogonal to the column space of A, (because $b_{projCol(A)}$ is a projection of b to Col(A)), the term is in the subspace Null(A$^T$).</p>
<p>Therefore, we multiply Ax&#x3D;b by $A^T$ to get rid of the term.</p>
<p>$A^TAx &#x3D; A^Tb$, <strong>normal equation,</strong> which has a solution (previous equation is un-solvable) as long as $A^TA$ is invertable,</p>
<p>$x &#x3D; (A^TA)^{-1}A^Tb$</p>
<p>$Ax &#x3D; A(A^TA)^{-1}A^Tb &#x3D;  b_{projCol(A)}$</p>
<p>here, $A(A^TA)^{-1}A^T$ is called the projection matrix that projects b into the column matrix of A.</p>
<h1 id="Determinants"><a href="#Determinants" class="headerlink" title="Determinants"></a>Determinants</h1><h2 id="Leibniz-Formula-for-calculating-determinants"><a href="#Leibniz-Formula-for-calculating-determinants" class="headerlink" title="Leibniz Formula for calculating determinants"></a>Leibniz Formula for calculating determinants</h2><p>$\det(A)&#x3D;\sum_{\sigma \in S_n}\text{sgn}(\sigma)\prod_{i&#x3D;1}^{n} a_{\sigma(i),i}$</p>
<p>where $sgn(\sigma)$ is +&#x2F;- when the permutation $\sigma$ needs even&#x2F;odd times of permutations from a normal order. $S_n$ is the permutation group.</p>
<h2 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h2><ol>
<li>Det I &#x3D; 1</li>
<li>det changes sign when row interchanges</li>
<li>det is a linear function of all rows. (<strong>multiply</strong> the first row by a constant, then det is also multiplied by the constant, <strong>add</strong> works in a similar way)</li>
<li>by 2 3: det &#x3D; 0 if there are equal rows</li>
<li>det D&#x2F;L&#x2F;U &#x3D; product of diagonal elements</li>
<li>Det(AB) &#x3D; detA * detB</li>
<li>Gaussian Elemination does not change the det</li>
</ol>
<h1 id="Eigenvalue"><a href="#Eigenvalue" class="headerlink" title="Eigenvalue"></a>Eigenvalue</h1><p>Given a matrix $A\in \R^{n\times n}$:</p>
<p>$Ax &#x3D; \lambda x $, $x$ is the eigen vector and $\lambda$ is the eigen value</p>
<p>That is, $(A-\lambda I )x &#x3D; 0$.</p>
<p>If $A-\lambda x$ can be inversed (the determinant is not zero), then x&#x3D;0 is a trivial solution.</p>
<p>Therefore, $A-\lambda x$ cannot be an invertiable matrix (det is zero)</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://wadmes.github.io/2021/03/29/Study-Notes-Learning-how-to-learn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/liwei3.jpg">
      <meta itemprop="name" content="Li Wei">
      <meta itemprop="description" content="人生注定是一个人的旅行，但就算孤独也要做一直前行的人啊">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NEWAY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/29/Study-Notes-Learning-how-to-learn/" class="post-title-link" itemprop="url">Study Notes: Learning how to learn</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-03-29 22:37:21" itemprop="dateCreated datePublished" datetime="2021-03-29T22:37:21-04:00">2021-03-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-31 11:40:15" itemprop="dateModified" datetime="2021-03-31T11:40:15-04:00">2021-03-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/study/" itemprop="url" rel="index"><span itemprop="name">study</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2021/03/29/Study-Notes-Learning-how-to-learn/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/03/29/Study-Notes-Learning-how-to-learn/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="General-Summary"><a href="#General-Summary" class="headerlink" title="General Summary"></a>General Summary</h1><h2 id="What-to-do-everyday"><a href="#What-to-do-everyday" class="headerlink" title="What to do everyday"></a>What to do everyday</h2><ul>
<li>Pomodoro</li>
<li>Before sleep, recap + prepared Daily TO-DO with a specfic ddl (8.00pm for example)</li>
<li>When you wake up, work on the most important and most disliked task first, at least one Pomodoro</li>
</ul>
<h2 id="What-to-do-general"><a href="#What-to-do-general" class="headerlink" title="What to do (general)"></a>What to do (general)</h2><ul>
<li><p>Ask questions (engaged in) during some disliked activities, e.g. boring lecture.</p>
</li>
<li><p>have a <strong>big picture</strong>. (For example, pre-view the chapter headings and figures before class)</p>
</li>
</ul>
<h2 id="What-not-to-do"><a href="#What-not-to-do" class="headerlink" title="What not to do"></a>What not to do</h2><ul>
<li>do not cram one time, learn by spaced repetition</li>
<li>do not worry about your product, which may discourage you and make you procrastinated</li>
<li></li>
</ul>
<h1 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h1><p><strong>Diffuse</strong>: Let the thinking flies by taking a showering, exercise …. When you are trying to propose new ideas, a diffuse mode is better.</p>
<p><strong>Sleep</strong>: New synapses are built.</p>
<h2 id="Reason-for-Procrastination"><a href="#Reason-for-Procrastination" class="headerlink" title="Reason. for Procrastination"></a>Reason. for Procrastination</h2><ol>
<li>feel unhappy</li>
<li>switch to a more plesant task</li>
<li>feel happy temperarily</li>
</ol>
<p>Solution: Pomodoro(番茄工作法): 25 minutes without internetrruption + a few minutes awards (diffuse mode)</p>
<h2 id="Practice-for-permanent"><a href="#Practice-for-permanent" class="headerlink" title="Practice for permanent"></a>Practice for permanent</h2><p>Math symbol is abstract, making it difficult to remeber and understand. However, we can remeber some abstarct symbols (like emotion). The reason is <strong>practice</strong>.</p>
<h2 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h2><p>Working memory(short term memory)：stored in an ineffecient blackboard</p>
<p>Long term memory: stored in an immense warehouse (need to repeat at lease a few times)</p>
<p>spaced repetition: better than practcing one thing for multiple times ONE DAY. （leave time for mortar 砂浆 to dry)</p>
<h2 id="Sleep"><a href="#Sleep" class="headerlink" title="Sleep"></a>Sleep</h2><ul>
<li>remove toxins when sleeping.</li>
<li>strength something important to learn </li>
<li>When you are sleeping, It’s as if the complete deactivation of the conscious you in the prefrontal cortex at the forefront of your brain helps other areas of your brain start talking more easily to one another, allowing them to put together the neural solution to your learning task while you’re sleeping. (diffuse mode) -&gt; focused mode learn before sleeping</li>
</ul>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>How to concertarte in something you dislike, e.g. a boring lecture?</p>
<p>A: Ask questions. Because you learn more when you are engaged in something.</p>
<p>Enriched enviorment is going to help you learning better. In the un-enriched enviorment, exercise will also help you.(new neurons are born ) : use your muscles rather than brain.</p>
<h1 id="Second-week-chuncks"><a href="#Second-week-chuncks" class="headerlink" title="Second week chuncks"></a>Second week chuncks</h1><p> <strong>Chuncks</strong>: compact packages of information that your mind can easily access</p>
<p>In you <em>foucs mode</em>, you generate chuncks.</p>
<h2 id="How-to-form-a-chunk"><a href="#How-to-form-a-chunk" class="headerlink" title="How to form a chunk?"></a>How to form a chunk?</h2><ul>
<li>First build some small mini chuncks (small music passages)</li>
<li>And then merge them together to form a chunk (john passages together to play a song)</li>
</ul>
<p>In math&amp;science, we learn some sample problems with worked out solutions.</p>
<p>Other important things:</p>
<ul>
<li>Docused attention</li>
<li>understand the basic idea</li>
<li>understand solutions to basic questions are not enough (you should be able to <strong>do it by YOURSELF</strong>)</li>
<li>You should have a <strong>big picture</strong>. (For example, pre-view the chapter headings and figures before class), so that you know when and which chuncks and constructed&#x2F;used, and how chuncks are connected to each other.</li>
</ul>
<h2 id="Illusions-of-Competence"><a href="#Illusions-of-Competence" class="headerlink" title="Illusions of Competence"></a>Illusions of Competence</h2><p>Try to remeber a piece of material?</p>
<p>BAD: re-read (re-study); Many underlining and highlighting</p>
<p>GOOD: <strong>recall</strong>-&gt;re-read(re-study)-&gt;recall; (in some sense linke test); recall when <strong>outside</strong> your usual study place.</p>
<p>More advaced study(after you know basic ideas): concept mapping</p>
<h1 id="Week-3-Procrastination"><a href="#Week-3-Procrastination" class="headerlink" title="Week 3: Procrastination"></a>Week 3: Procrastination</h1><p>Willpower is not easy. Do not waste willpower on fending off procrastination except when necessary. </p>
<h2 id="Habits"><a href="#Habits" class="headerlink" title="Habits"></a>Habits</h2><p>Four parts:</p>
<ol>
<li>Cue（信号，也有皱眉的意思）not neither helpful nor harmful. It is our routine that matters.</li>
<li>Routine (Zombie mode)</li>
<li>Reward</li>
<li>Belief</li>
</ol>
<p>Procastination is a simple habit that follows the four steps above</p>
<h2 id="Process-vs-Product"><a href="#Process-vs-Product" class="headerlink" title="Process vs. Product"></a>Process vs. Product</h2><ul>
<li>To avoid procrastination, concentrate on process instead of product. </li>
<li>Process relates to simple habits that coincidentally allow you to do unpleasant task</li>
</ul>
<p>For example, a hard homework</p>
<ul>
<li>avoid focusing on the product: the answers to the questions</li>
<li>Focus on doing a Pomodoro (番茄工作法), a 25-minutes work session</li>
</ul>
<h2 id="How-to-overcome-pricastination"><a href="#How-to-overcome-pricastination" class="headerlink" title="How to overcome pricastination"></a>How to overcome pricastination</h2><ul>
<li>Plan: <ul>
<li>develop a new ritual（仪式）, e.g. leave your phone in the car when attending class. May not work perfectly a first.</li>
<li>Weekly list + daily TODO list with a quitting time (write this before you go to sleep)</li>
<li>Work on the most important and most disliked task first, at least one Pomodoro</li>
</ul>
</li>
<li>Reward</li>
<li>believe your system will work</li>
</ul>
<h1 id="Week-4-How-to-Become-a-Better-Learner"><a href="#Week-4-How-to-Become-a-Better-Learner" class="headerlink" title="Week 4: How to Become a Better Learner"></a>Week 4: How to Become a Better Learner</h1><ul>
<li>exercise</li>
<li>metaphor or analogy</li>
<li>Change your thoughts and admit the mistake</li>
<li>work with other person to avoid blind spot (but should not be a socialization group)</li>
<li>For test:<ul>
<li>start hard, jump to easy</li>
<li>this test makes me afraid -&gt; this test makes me determined to do my best!</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://wadmes.github.io/2020/10/13/%E8%AE%B0%E9%AB%98%E6%AD%A6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/liwei3.jpg">
      <meta itemprop="name" content="Li Wei">
      <meta itemprop="description" content="人生注定是一个人的旅行，但就算孤独也要做一直前行的人啊">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NEWAY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/13/%E8%AE%B0%E9%AB%98%E6%AD%A6/" class="post-title-link" itemprop="url">记高武</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-10-13 21:36:34 / Modified: 10:53:50" itemprop="dateCreated datePublished" datetime="2020-10-13T21:36:34-04:00">2020-10-13</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/life/" itemprop="url" rel="index"><span itemprop="name">life</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/10/13/%E8%AE%B0%E9%AB%98%E6%AD%A6/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/10/13/%E8%AE%B0%E9%AB%98%E6%AD%A6/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>然后到了我的管家，高武了。他是高二来到我们班的，一开始他孤僻的性格加上奇葩的声音使他看起来很不合群，还经常被我们201耻笑…后来他坐到了我后面，可能由于我看他老实吧，他成了我管家，帮我打理琐碎事务，说来惭愧，作为我的管家我愣是没给过他工资。（后来玩开后笑萍一直拿这个怂恿高武，搞得后来他越来越不老实了。）高武是个胸有大志的人，但他的志向从来不会告诉别人，我还是在他的本子上看到密密麻麻的笔记才知道的，因为那笔记只包含了四个字——武定中原…霸气！同样的，他也不会说出自己的心事，我知道他有心事——他的家庭，他的前途，他的成绩，但他一概不提，他总是一个人憋在心里，他会午睡时一个人孤独的成四十五度角仰望窗台外明朗的天空和远方如中国画一般墨绿的山峰，他会睡觉时翻来覆去思考与他有关的一切事，他会在他许多很“非主流”的本子上记下他所思所想，这也许是他的思考方式吧。</p>
<p>额，在这里研究他的心理似乎有点不厚道，不说这方面了。</p>
<p>高武不善言辞，很多时候都是默默的承受，还是我最压抑的日子，他从没鼓励我什么的，但高考完，小姨问起我我们班有没有人名字里有个武，那时我才知道，原来高武一直发短信给我小姨，让我小姨来安慰我。听完我内心诧异了许久，原来那个呆呆木木的高武也会关心人诶，原来世界上还有许多人挂念，关心着我，这种感觉真是别样的幸福。</p>
</blockquote>
<p>这段是我高中刚毕业时写下的和高武有关的回忆。我觉得我有一些需要补充的必要。我第一次和高武的接触应该是由此在201讨论他的时候：应该是说他奇怪的声音和某些特点，譬如止不住的咳嗽？总之睡在宿舍门口上铺的我看到了高武正在偷听：那个瘦弱矮小性格冷淡的男生正侧着身子将耳朵放到门边听着我们对他的讨论，我已忘记我们是否带着嘲讽意味，但愿没有。</p>
<p>后来他坐我后面，具体怎么成了前后桌的我也忘了，不过很高兴的是我并没有对这个有点“被排挤”的同学有一点不满或是不乐意接触的意思。记得班上有过另外一个新来的同学也是经常咳嗽，结果她前排的那位同学对此很不满，总是觉得她咳口水到自己的头发上了，这方面我倒是无所谓，毕竟我自己就很邋遢。</p>
<p>总之成了前后桌之后我和他的关系直线上升，直至经常一起吃饭。我比较邋遢，爸妈给的钱和一些零钱也总是扔在一起，见高武整理的井井有条，便索性委托高武帮我管理财物。还称之为管家。甚至都达成了少年之约，待我功成名就需要管家的时候，一定请高武来当我家总管。学习上，虽然我偶有教高武一些我的学习方法，不过他也不怎么问我题目，可能和很多同学一样，不想因为问题太简单被我耻笑吧。</p>
<p>高中毕业后，高武也曾联系我，问我“李巍，你现在过的怎么样？”。我过了很久才看到消息，回到“很好啊，高武，你呢？”。然后便没有下文了。这也是我最追悔莫及的一点，倘若我早点回复，或者跟高武继续聊天保持联系，至少我还能在他身前给他更多的一点温暖。</p>
<p>这是我能补充的所有片段了，我再怎么想，也没有一个向后的时光机可以倒转。不过再翻看上面的回忆，这个天然前进的时光机倒是让有些问题在现在得到了答案，譬如他的家庭、他的前途、他的心事，我总算了解了一些，虽然为时已晚。高武本身家庭就很贫困，他家在一个离镇上都还有接近两小时车程的山沟沟里，我问了当地村长，还好那个地方和镇上每天都有班车来回，不过即便如此高武往返学校来回都需要至少十小时的车程。出发前我其实对找到高武的住处也有着一丝担忧，我只知道他是哪个村的，其他一概不知，万幸我在乡卫生所，其实也就是一个很小的医药门面，碰到了他们村的村长，在村长的指引下，我找到了他的住处。他父亲当时正在收割稻田，村长下田里叫他，叔叔便赤着脚走回了家里，脚上还沾满了水田里的泥土。高武是在过年的时候在他姑父家出的意外，当时他帮姑父一家拍照一直往后退，便不慎跌下楼。骨灰也留在了姑父家，没有带回来。他的妈妈因为吃农药过世了，我不清楚是高武去世前还是之后，但总之他父亲现在一个人孤苦伶仃的生活着。我随着叔叔进了门，看着基本家徒四壁的光景，想到我本应该很早就来他家里看看，我眼泪又止不住的流。但是我没有像第一次知道消息时一直痛哭，我内心告诉自己不能再流泪了，高武的爸爸才是最伤心的那个人，我不能再勾起他更多的痛苦的回忆。我将买的水果牛奶给了叔叔，但是他硬是拒绝了我给的钱，无奈，我只能加上叔叔的微信，告别了高武的故乡。</p>
<blockquote>
<p>说到高中，自从知道了那件事后，很不想再和过去的时光有什么瓜葛：有点我以我心对明月，奈何明月照沟渠的意思。但是对于高武，确实是让我感动到耿耿于怀的：那个在草稿本上写满武定中原，看起来深不可测的高武，高考前两个月一直和我小姨发短信说我压力很大让小姨安慰安慰我。高中刚毕业时，对于这些，粗线条的我只是感动，然后一带而过。但现在越发觉得，要做到这一步，实在是太无私伟大了。人生在世，大多数人只是为了自己：和你相处是为了自己的前途或是为了自己能开心，倘若你对我的前途无用、或是你惹的我不开心了，我屁股一拍就可以溜了，临走时还可以忿忿道对方如何如何不好。而像高武，便是我钦佩和想成为的，温暖而不张扬，照顾他人情绪而不仅仅是为了自己。可惜的是高中后便和他断了联系，纵使一直qq找他也了无音信。</p>
</blockquote>
<p>上面这段，是今年四月份我碎碎念时念叨的关于高武的片段。当时我还不知道高武的噩耗，我只当高武和我无数同学朋友一样，只是有了各自的生活所以少了联系，但当再次遇见时，便又能相视大笑，共忆少年时。</p>
<p>直到我再赶ICCAD的前一两个星期，无意中得知了他的意外。一瞬间我的双脚像没了知觉一样瘫倒在地，我倒在地上嚎啕大哭，脑子里一片空白，只有难过。我哭了不知多久，把自己眼泪哭干了，力气哭没了，肚子哭饿了，便去找水喝，可是水也拿不稳，我便继续倚在打水的台子上哭。</p>
<p>距离高武离开已经快六年了，距离我知道这个消息也半年了，但终究仍然莫名其妙有一些时刻，那种难以置信、悲痛欲绝的感觉会涌上我的心头。我是个缺爱的人，也因此我很珍惜那些温柔的、会表达爱的、无条件对我好的人。可惜当我认识到自我、认识到哪些人是这样的人的时候已经晚了。不过按照活在心中便不是死亡的概念，高武一直不会离去，我也要带着他的温柔，和他一样，做一个体贴、无私、善良的人。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://wadmes.github.io/2020/10/03/after-ICLR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/liwei3.jpg">
      <meta itemprop="name" content="Li Wei">
      <meta itemprop="description" content="人生注定是一个人的旅行，但就算孤独也要做一直前行的人啊">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NEWAY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/03/after-ICLR/" class="post-title-link" itemprop="url">After ICLR 2021</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-10-03 20:17:18" itemprop="dateCreated datePublished" datetime="2020-10-03T20:17:18-04:00">2020-10-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-12-29 21:34:53" itemprop="dateModified" datetime="2021-12-29T21:34:53-05:00">2021-12-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/life/" itemprop="url" rel="index"><span itemprop="name">life</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/10/03/after-ICLR/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/10/03/after-ICLR/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Hey Neway。这里是2020国庆刚刚过去的秋天。</p>
<p>现在的我刚刚在十四天隔离里赶完了ICLR21的paper，坐在回家的高铁上。本来应该是要休息下的，毕竟这一星期实在是太累了。但是高铁上终究还是没有床上舒服，干脆先写完一些碎碎念吧。</p>
<p>这篇target ICLR的paper是我第一次做GNN的理论尝试，其实也只是做了一些微小贡献。。（emmm。。真的是很trivial的东西）。大概就是formalize 了GNN for graph coloring的power 然后给出了一些power下降的情况。其实最后投出去那么几十分钟还是很开心的，对自己也是比较满意的：起初以为是自己对paper的满意，后面深究一下才觉着其实是对自己的满意：满意自己没有半途而废 最后还是把论文投出去了。关于论文、科研，我还没有一个成型的philosophy，只是有个大概的感觉，我做的东西只是把它当作自己的孩子，我重视、爱惜、不放弃就够了，至于真的能让人类知识圈往外扩一点点么，就不得而知了，我目前也没有很关心这个东西，我好像还是很功利性的考虑自己的paper，i.e., 我指望自己的paper能中就行，而又因为paper总是可以中的，所以无需指望自己的paper能做什么。。。这个思想。。其实有点奇怪。。就好比，一个父母自诩我只是单纯的对孩子好，只指望他能找到工作就行，而我们生活在就业率百分百的国家，所以无需指望我们的孩子要达到什么要求。但找到工作本身就是要求了，万一就业率不是百分百了呢。类似的，能中paper本身就是要求了，万一以后没有recycle了呢。</p>
<p>不过也不能太苛责自己了吧。毕竟我处在一个很需要“中了”的paper的关键阶段。但是要发一篇当之无愧能中的paper真的好难啊。这是我这段时间别搞研究别学托福总结的残酷事实：相比起学习，科研难太多了。不论是学英语、学数学、学编程，走任何前人趟过的、在走不过的地方还标着此处绕道的泥泞，比起走一条黑不溜秋充满未知的路，简单太多他多太多了。我都不知道有多少个夜晚，我埋在枕头里冥思苦想，在ipad上划来划去，也没有任何有益结论了。每每这时，就有一种书到用时方恨晚，有时间了一定要好好重学微积分、组合优化、概率论、矩阵运算等。</p>
<p>其实这一两年给自己留了很多有时间了一定要xxx的坑。直接放个前几天大晚上赶ICLR神经兴奋睡不着写的备忘录吧：</p>
<blockquote>
<h1 id=""><a href="#" class="headerlink" title=""></a></h1><p>失眠夜的一点想法，</p>
<p>等托福考完，陶瓷搞完，文书写好，申请结束之后：</p>
<p>一定要做好多现在因为ddl做不了的事</p>
<p>譬如把线代微积分这些基础知识再好好的过一遍；</p>
<p>譬如认真像学习一样的的尝试上一次英雄联盟钻石；</p>
<p>譬如把你不要担心的吉他谱学会；</p>
<p>譬如化身林克把公主救了；</p>
<p>譬如把买了一直没玩的奇异人生大镖客gta5通关一次顺便再写点感想；</p>
<p>倘若还有点时间，试着做点视频。</p>
<p>除了申请结束后的那几个月，真正属于我自己的，自由的时间，不多了啊。</p>
</blockquote>
<p>时间呐时间，就是这样匆匆不等人。永远在催着你上路。几个月后，我就要知道我PhD会去哪了。这种对未来未知但又饱含希望的感情，就是我很喜欢hey kong这首歌的原因:</p>
<blockquote>
<p>kong 这种日子到底还有多久，我到底能不能成为说唱歌手。</p>
</blockquote>
<p>neway啊，这种日子到底还有多久，我到底能不能成为一个问心无愧的大学教授。我未来到底会去哪个国家，去哪所大学，做什么方向，成为什么样的人。这些我都不知道，但也都想知道。</p>
<p>好了最后再说说结婚这件事吧。五月份找她和好之后，虽然和好了，但也能明显感觉到其实她不爱自己了。比如香港到深圳隔离没理她，她生气，我解释安慰她说中间事情很多，然后提到我还哭了。但是她也像没听到一样没有在意。再然后基本上是我找她，她回得也比较少。</p>
<p>还是挺难过的。因为很早时候父母的离婚和童年寄人篱下的颠沛流离的回忆，感觉自己还是一个很需要情感支持的人。不过也许，至少我现在一直抱着这样的希望，人的交往或多或少是像镜子一样，我持续的像wuli崔泽一样，先好好爱一个人，也许她会报之以琼瑶？</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://wadmes.github.io/2020/07/20/Hey-Kong%EF%BC%8CJuly%EF%BC%8C2020/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/liwei3.jpg">
      <meta itemprop="name" content="Li Wei">
      <meta itemprop="description" content="人生注定是一个人的旅行，但就算孤独也要做一直前行的人啊">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NEWAY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/20/Hey-Kong%EF%BC%8CJuly%EF%BC%8C2020/" class="post-title-link" itemprop="url">Hey Kong，July，2020</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-07-20 02:16:29" itemprop="dateCreated datePublished" datetime="2020-07-20T02:16:29-04:00">2020-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-07-19 14:53:06" itemprop="dateModified" datetime="2020-07-19T14:53:06-04:00">2020-07-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/life/" itemprop="url" rel="index"><span itemprop="name">life</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/07/20/Hey-Kong%EF%BC%8CJuly%EF%BC%8C2020/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/07/20/Hey-Kong%EF%BC%8CJuly%EF%BC%8C2020/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Hey，Neway。这里是2020年炎热的夏天。</p>
<p>2020年可能是你这辈子一提起都会感慨一些事的一年：噢那年啊，那个新冠可是持续了一年，我戴了一年口罩，在宿舍办公了一年；噢那年中美彻底撕破脸了；对我来说，除了这些国家大事，自己的人生也是在一个重大的转折点上，这也是我为什么想给你写封信，而不是按之前那样，碎碎念的记录日子：不知道这个转折点后的你，会在哪里，带着什么样的心情读这封信，所以也是蛮有意思的。</p>
<p>其实你也知道这个转折点是什么意思：今年是准备申请的一年，现在是7月20日，我也背了快2&#x2F;3的单词了，但是每次复习的时候还是有很多单词不认识。教授也还没开始套瓷，感觉教授们的方向没有一个和我特别match，做GCN的没有做EDA的，做EDA的没有做GCN的。没套瓷还有另一个原因：ICCAD没中啦。</p>
<p>感觉写的像野马奔腾一样没有主线，那就先说说ICCAD没中这件事上。给个评价的话，算是意料之中但又出乎意料吧，意料之中是因为实验都没做完，test layout只拿了一个circuit，其他的实在是跑不完了；就这一点就足够杀掉这篇paper了。意料之外是这个work比起DAC那篇是让我满意特别多的work；是一个让我觉得自己不是一个只知道套DL SOTA的缝合怪的work；也是一个可以让我特别自豪的showoff的work。哎，所以知道没中的时候真的还是感觉好可惜呐，本来还想着iccad也直接中，就可以底气十足的抬头挺胸去套瓷了，但现在就很尴尬了，申请前我能投的paper除去这篇recycle到ASPDAC的就只有一篇target ICLR的work了，而且也没有recycle的机会了。。。哎，只能安慰自己publication并不算很重要吧。</p>
<p>除去对我申请的直接影响，这次没中还让我给自己一个清晰的认知：或者说是泼了一盆冷水，虽然自诩想当威斯布鲁克不想当科沃尔，但是真没中需要recycle的时候还是让我明白，我不是什么特别适合research的天才。基于此，有个最近困扰我很久的更严重的问题：所谓德不配位，我这种水平的臭弟弟，就算侥幸伸到了四大的PHD，进去后真能做出什么影响整个圈子的work吗？哎，每每想到这，心情就沉重了三分，如人饮水，冷暖自知，自己的水平是怎样的，只有自己最清楚，就像初高中随随便便就能考第一，大一大二翘一学年课都能拿A，是因为知道自己就是比起其他人强，但是真的到了PHD要搞research到时候，也是能清楚感觉到自己读的书太少！”书到用时方恨少“哪！高三可以几个月把高一高二三国杀+奥赛落下的吃完，但是真的面对人类边界的那些数学知识，我也实在只是一个普通人哪，尤其是最近读GCN相关的理论paper，那些证明只能让我感慨妙哉，让我来写我却只能摸摸脑壳。英雄联盟有个玩笑话:</p>
<blockquote>
<p>不是你的分段，你不要碰</p>
</blockquote>
<p>放到研究里，不也有</p>
<blockquote>
<p>不是你脑子能搞懂的领域，你不要碰</p>
</blockquote>
<p>我很自信我的水平是当得起香港中文大学博士的，但是，譬如让我成为一个MIT的博士，我只能呵呵了。这就是别人常说的，欲戴皇冠，必承其重吧。</p>
<p>但是我终究还是要努力去申请的。这也是这段时间想通的。关于随遇而安和尽吾志也的关系。我一直都是一个随遇而安的人，也因此对很多东西没什么追求动力。让我转变想法的是关于高中的一段话，大意就是高中是最美好的时光，因为它代表着无限的可能，代表着无限的选择。随着开始准备申请，我意识到，自己的学习能力是在逐渐下降的，而这种下降，也意味着自己未来选择的权利和机会是越来越少的。同时，作为一个master，而不是PhD student，我还有也是仅有申请PhD这最后一个机会，来提高自己的可能性。所以，在学习能力还在巅峰的最后几年，去努力成为自己想成为的人，才不至于让自己在没有这个学习能力，没有这个申请机会的时候叹息后悔。这才是“尽吾志也而不能至者，可以无悔矣”的真义哪，先有尽吾志也，才有无悔。哈哈，原谅我这个年轻人对于人生观的多变，不知道2030年的你看到这些会是怎样的想法，又会有怎样的人生观，这也算是我们生而为人很奇妙的一件事吧。</p>
<p>啊，其实还有很多sub-topic想说，但是已经三点了，我实在是得睡了，所以下次再说吧。最近总是中午才起床，拖拖拉拉就是两三点才开始办公，事情都拖着，每天还要两小时背单词，之后一定得最大化利用时间了！</p>
<p>Fighting!</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://wadmes.github.io/2020/06/27/GlobalRouting/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/liwei3.jpg">
      <meta itemprop="name" content="Li Wei">
      <meta itemprop="description" content="人生注定是一个人的旅行，但就算孤独也要做一直前行的人啊">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NEWAY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/27/GlobalRouting/" class="post-title-link" itemprop="url">Global Routing</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-06-27 02:01:52" itemprop="dateCreated datePublished" datetime="2020-06-27T02:01:52-04:00">2020-06-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-05-24 11:46:15" itemprop="dateModified" datetime="2023-05-24T11:46:15-04:00">2023-05-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/study/" itemprop="url" rel="index"><span itemprop="name">study</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/06/27/GlobalRouting/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/06/27/GlobalRouting/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://wadmes.github.io/2020/06/27/%E8%B6%85%E7%B2%BE%E7%AE%80%E7%9A%84GCN%E7%BB%BC%E8%BF%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/liwei3.jpg">
      <meta itemprop="name" content="Li Wei">
      <meta itemprop="description" content="人生注定是一个人的旅行，但就算孤独也要做一直前行的人啊">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NEWAY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/27/%E8%B6%85%E7%B2%BE%E7%AE%80%E7%9A%84GCN%E7%BB%BC%E8%BF%B0/" class="post-title-link" itemprop="url">超精简的GNN综述</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-06-27 01:01:52" itemprop="dateCreated datePublished" datetime="2020-06-27T01:01:52-04:00">2020-06-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-05-01 19:05:43" itemprop="dateModified" datetime="2022-05-01T19:05:43-04:00">2022-05-01</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/study/" itemprop="url" rel="index"><span itemprop="name">study</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/06/27/%E8%B6%85%E7%B2%BE%E7%AE%80%E7%9A%84GCN%E7%BB%BC%E8%BF%B0/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/06/27/%E8%B6%85%E7%B2%BE%E7%AE%80%E7%9A%84GCN%E7%BB%BC%E8%BF%B0/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>前言。本文作于GCN横空出世（2017）的三年后（2020），想尽可能在简单易懂的情况下说清楚近年GNN的发展脉络。当然，凭我鸽子王的尿性，估计本来也就不会写的很翔实（简单是第一层，偷懒是第二层🐶）。</p>
<p>4th, March, 2021. Update: After a series of rejections by AI conferences, I note that I may look back on these papers and rethink why these papers can be accepted, i.e., review them in a positive and admired way instead of criticising them. Also, I try to pay attentions to the authors and institutes, and summarize the research style of different groups. This helps to understand the whole GNN community and “may” contribute to my PhD dicision.</p>
</blockquote>
<p>最近GNN又看了一些ICLR2020的paper，加之之前积累的paper，对整个GNN的发展脉络有了比较清楚的理解，之所以想要记录在案，是因为发现：</p>
<ul>
<li>GNN有点类似CNN，是一个入门难度不高，效果又比较出色的技术。不像EDA里面各种子问题及现在的SOTA解决方案，要解释清楚就要半天。</li>
<li>现在的各种文章因为作者们的严谨及数学功底的雄厚，导致涉及内容过多，我要真正看明白的阈值太高（对不起实在是因为我太菜了），因此心里琢磨着要是能有一篇浅显易懂的综述，快捷的理清paper间的区别和发展脉络该多好。</li>
<li>现在许多GNN的paper其实真正technique部分的contribution很容易概括，当然所谓的research也不可能是一蹴而就 novelty、results什么的全都完爆previous work。只是很多paper的出发点都不一样，导致看起来paper间差异很大，其实在我看来现在GNN还是一个比较混沌的状态，等着哪位X kaiming大神来盘古开天。（或者说GCN这篇就算是开天了？）</li>
</ul>
<p><strong>Note：这篇文章完全是为我本人量身打造，是为了未来的我复习GNN的时候有个参考。因此我面向的读者是有了比较充足的CNN、Graph知识背景的。</strong></p>
<h1 id="开山老祖-GCN"><a href="#开山老祖-GCN" class="headerlink" title="开山老祖 GCN"></a>开山老祖 GCN</h1><blockquote>
<p>这一段大部分是我的臆测。。可以直接看结论。</p>
</blockquote>
<p>给一个irregular的grpah&#x2F;point cloud，我们可以从频域(specture)和空间(spatial)角度去解决这个问题</p>
<ul>
<li>频域角度就是图信号映射到频域后再做卷积操作。（直接copy from zhihu，原谅我这一块其实并不是很清楚，因为现在的大部分work都不会提specture这个东西了。。。而且本身这个对数学功底要求就有点高，也许我真的phd了可以花时间研究这个？单就目前纯水paper的角度，这个建议不要碰，1.上手难，2.现在大部分SOTA都是spatial）</li>
<li>空间角度大概就是直接从点&#x2F;线的关系入手，用这些关系来表示某种message passing。messgae passing的意思很简单，就是说给一个点，它会把它自己的信息（feature）传输给它的邻点，同样，它的邻点也会把邻点的信息传给它。大概有点像社会学里面的信息传输，譬如李巍长得很帅，一传十十传百所有人都知道我长得很帅这样。。（我长得很帅这个信息就被所有人收到了，这样在他们那的信息就是：我有个朋友&#x2F;朋友的朋友长的很帅）</li>
</ul>
<p>这篇GCN做的就是，从频域角度出发给了GCN的公式：</p>
<p><img src="https://www.zhihu.com/equation?tex=H%5E%7B(l+1)%7D+=+%5Csigma+(%5Cwidetilde+D+%5E%7B-%5Cfrac%7B1%7D%7B2%7D%7D+%5Cwidetilde+A+%5Cwidetilde+D%5E%7B-%5Cfrac%7B1%7D%7B2%7D%7D+H%5E%7B(l)%7DW%5E%7B(l)%7D+)+%5C%5C+%5C%5C" alt="[公式]"></p>
<p>$H^l$就是第l层的所有点的feature，$\bar{A}$是加上identity matrix的矩阵，D是degree matrix为了normalization（结果其实比较接近mean），W就是映射到另一个空间增加信息量。</p>
<p>然后发现这个公式其实可以从空间的角度很elegant的解释，GCN的每一层其实就是aggragation + combing（encoding）</p>
<ul>
<li>$\bar{A}H$ 其实就是对于任何一个点，将自己的feature，以及邻点的feature 累加起来，加个D就是为了normalization（$D^{-1}$ 其实就是mean），因为每次都累加层数多了这个值不爆炸了？而且有些点邻居本来就多怎么办？。</li>
<li>$W^{l}$ 就是做一次combing啦，可以理解成投射到另一个空间增加复杂度（其实就是1*1conv，or FC，or MLP，哦，有的可能还会加个bias）</li>
</ul>
<h1 id="方法层面"><a href="#方法层面" class="headerlink" title="方法层面"></a>方法层面</h1><h2 id="GraphSAGE"><a href="#GraphSAGE" class="headerlink" title="GraphSAGE"></a>GraphSAGE</h2><p>这篇就直接不管specture了，直接从空间角度把GCN重新提了一遍，同时formally定义了aggregator这个概念，其实就是对于每个点，怎么将它自己及它邻点的信息聚合（aggregate）起来。然后还提出了几个方法。</p>
<ul>
<li>不加自己的feature mean 。</li>
<li>加上自己的feature mean。。。</li>
<li>LSTM。。。也许那个年代LSTM比较火吧。</li>
<li>channel-wise的max sampling</li>
</ul>
<p>注：aggregator其实总之不管是什么，都只要保证order-invarienty以及size-insensitivity就行了</p>
<h2 id="GAT"><a href="#GAT" class="headerlink" title="GAT"></a>GAT</h2><p>这篇就是说attention效果这么好，我们也套用到GCN吧！（对不起这是我的小人之心🐶），实际上应该是：每个邻居可能重要性不一样，所以要加个attention！</p>
<p><img src="https://www.zhihu.com/equation?tex=a_%7Blearn%7D(i,j)=%5Cfrac%7Bexp(LeakyReLU(w%5BWx_i,Wx_j%5D))%7D%7B%5CSigma_%7Bk%5Cin+neigh(i)%7Dexp(LeakyReLU(w%5BWx_i,Wx_k%5D))%7D%5C%5C" alt="[公式]"></p>
<p>a(i,j)就是点i对点j的重要性。但这个真把我秀到了，具体可以参见<a href="https://wadmes.github.io/2019/12/30/attention/">https://wadmes.github.io/2019/12/30/attention/</a></p>
<h2 id="JKNet"><a href="#JKNet" class="headerlink" title="JKNet"></a>JKNet</h2><p>这篇就是说DenseNet效果这么好，我们也套用到GCN吧！（其实background还是GCN层数过深，例如depth&gt;2，就会出现oversmooth的情况，即所有离得近点的feature长的都挺像的。而离得远的点互相的connection又太小了，所以加个densenet就可以让他们connection不小了呀呀呀呀呀呀）</p>
<blockquote>
<p>提到oversmoothing了就说下，其实直接原因是目前GCN的aggregation必须保证order invarienty，导致不像CNN里面的convolution kernel一样卷积时候可以带weight，想象一下CNN里面a pixel的右边是b pixel，传信息的时候用的是3*3kernel里面的(2,3)value，而b要传给a，就是(2,1)了，两个值不一样，所以不管传多少次都不会最后比较接近，除非(2,3) &#x3D; (1,3)，这就是GCN现在的情况，因为GCN不可能还有方向这个概念，或者说，给一个点a，他有邻居b，c，目前还不可能能分出b，c。。</p>
</blockquote>
<h2 id="DeepGCN"><a href="#DeepGCN" class="headerlink" title="DeepGCN"></a>DeepGCN</h2><p>这篇就是说ResNet效果这么好，我们也套用到GCN吧！</p>
<p>然后除了简单的加个residual connection，还提出了一个GCN上的dialated convolution，个人觉得是比residual 更重要&#x2F;有效的一点。大概就是：regular CNN里面dialated convolution可以很轻松的跳一个选一个这样卷积，但是GCN不好操作因为每个点邻居个数都不一样，而且还是无序的。这里的做法就是对于每个当前点，给其他点按照feature的欧几里得距离来个排序，然后就可以跳一个选一个啦！（其实有点做point cloud里面dynamic graph CNN那味了）</p>
<h2 id="Dropedge"><a href="#Dropedge" class="headerlink" title="Dropedge"></a>Dropedge</h2><p>这篇就是说Dropout效果这么好，我们也套用到GCN吧！</p>
<p>不过这里的dropout其实不同于CNN里面对feature的dropout（其实对feature的dropout在original GCN就用了），而是对weight的dropout，即每一层有概率的remove edge，（脑补一下，其实就相当于把GCN的weight全为1 改成了有些为0有些为1啊！）</p>
<h2 id="Position-aware-Graph-Neural-Networks"><a href="#Position-aware-Graph-Neural-Networks" class="headerlink" title="Position-aware Graph Neural Networks"></a>Position-aware Graph Neural Networks</h2><p>这个不是借用CNN的一些technique的理念，说下大概思路吧。</p>
<ul>
<li><p>问题：GCN只能捕捉局部的structure 信息，比如：</p>
<p><img src="/figures/image-20200627214400158.png" alt="image-20200627214400158"></p>
<p>不管怎样$v_1,v_2$（structurally isomorphic nodes）都是分配同样的label。那么怎么解决这个问题呢？</p>
<blockquote>
<p> node position can be captured by a low-distortion embedding by quantifying the distance between a given node and a set of anchor nodes</p>
</blockquote>
</li>
<li><p>先说下workflow吧，</p>
<ul>
<li>给$clog^2n$个子集$S_{i,j}，i&#x3D;1…\log n,j&#x3D;1,…,c\log n$，每个子集会随机选择所有点，每个点被选中的概率为$1&#x2F;2^i$,所以其实子集的大小其实是指数型增长的</li>
<li>PGNN的每一层operation如下，<ul>
<li>对于每个点，和每个子集里面的所有点（假设n个点）的featrue(假设d维) concat 起来-&gt;$n\times 2d$，如果子集里的点是距离为$k$外的（太远了），则return  zero值（而不是concat feature）。接着把concat结果aggreate起来-&gt; $2d$ （注意这里的aggregate也需要满足order invarianty！所以也只能用mean，max，sum等，作者直接用的mean）</li>
<li>对于不同的子集的结果再用aggregate $c\log^2n \times 2d \rightarrow 2d$。</li>
</ul>
</li>
</ul>
</li>
<li><p>总结：这篇的theorem用了Bourgain Theorem去证明只要$c\log ^2 n$个就子集就可以preserve the distances in the original graph with low distortion。。。不过很多paper里面的theorem都是比较巧妙的，让人觉着遥不可及。但是这个work解决GCN只有local structrue的大概方法也是类似的：就是想方设法的介绍一些global information进去，这里是通过介绍子集的方法，相当于给子集中的每个点多了一个额外信息：属于哪个子集。打个比方，假设所有人只有性别这一个label，我和坤坤都只有三个男性朋友，一个女性朋友，这样一层GCN就无法通过信息传输判断我的label了，但是如果创造2个子集（身份），分别是 爱rap的同学 和 爱打篮球的同学，然后发现我有一个爱rap的同学，2个爱打篮球的同学，坤坤有3个爱rap的同学，这样我和坤坤的label就是不一样的了。</p>
</li>
</ul>
<h2 id="COLORING-GRAPH-NEURAL-NETWORKS-FOR-NODE-DISAMBIGUATION"><a href="#COLORING-GRAPH-NEURAL-NETWORKS-FOR-NODE-DISAMBIGUATION" class="headerlink" title="COLORING GRAPH NEURAL NETWORKS FOR NODE DISAMBIGUATION"></a>COLORING GRAPH NEURAL NETWORKS FOR NODE DISAMBIGUATION</h2><p>引入了universal representations &amp; separability的概念，claim MPNN不是一个universal representation。解决方法（甚至出发点）和上篇paper有点相似。大概就是给node attribute 相同的点 从k种颜色中随机选一个颜色标上，k为hyper parameter，这样就实现了universal approximation。有两个concern</p>
<ul>
<li>若k不为 graph size （即所有点颜色都不一样），那么这种coloring sheme不是permutation invariance。这也是ICLR被拒的原因。</li>
<li>k&#x3D;1时，不就是所有点assign一个相同的颜色么。。没看懂。。。</li>
</ul>
<h2 id="GeomGCN"><a href="#GeomGCN" class="headerlink" title="GeomGCN"></a>GeomGCN</h2><p>同样，这个也不是借用CNN，说下大概思路吧。</p>
<ul>
<li><p>问题：1. 就像GIN说的（就这篇下面👇），现在基于聚合的都是垃圾，因为会将部分Non-isomorphic的图也给出同样的结果，如</p>
<p><img src="/figures/v2-7a1237527813b338926f6632bea84720_b.jpg" alt="img"></p>
<ol start="2">
<li>同样的 有些graph里面可能有些子图其实是有相似结构的，那么为什么不利用起来呢？</li>
</ol>
</li>
<li><p>基于以上两点，可以大概构思怎么解决 1. 将不同的node 当作不同的neighbor来聚合 2. 给每个node 加上一个能表示局部结构的node （这样局部结构相同的两点其实就可以share同样的feature了）</p>
</li>
<li><p>所以大概workflow如下：</p>
<ul>
<li>给每个点计算latent space上的node embedding，注意此处的node embedding是仅仅包含local struture 信息的（原文用了一些GCN之前的获取node embedding的方法，真的很纳闷为什么不直接用SOTA的GCN来获取node embedding）</li>
<li>对于每个点centroid，它都有两种邻居：真实邻居，转化成latent space下的邻居（另一个时空下的恋爱🐶），然后将每个邻居按照与centroid在latent space中的位置关系分为不同的邻居（为了解决第一个问题）。这里的实验latent space是二维的，所以邻居只分了四种，左上右上左下右下。</li>
<li>这样对于每种邻居，我们就分了四种点，这样就有四个aggregator，最后四个aggregator结果concat起来就行（因为总得保证是固定个结果嘛）</li>
</ul>
</li>
</ul>
<h2 id="Generalization-and-Representational-Limits-of-Graph-Neural-Networks"><a href="#Generalization-and-Representational-Limits-of-Graph-Neural-Networks" class="headerlink" title="Generalization and Representational Limits of Graph Neural Networks"></a>Generalization and Representational Limits of Graph Neural Networks</h2><p>定义decide：一个GNN Q如果decide了一个图性质P，则说明图性质P不同的两个图，由Q产生出来的graph embedding也肯定不同。</p>
<p>这篇文章前半部分就是用一些例子证明了：</p>
<ul>
<li>（用一些反例）基于聚合的很多GNN不能decide很多很简单的性质。</li>
</ul>
<h2 id="Simple-and-Deep-Graph-Convolutional-Networks"><a href="#Simple-and-Deep-Graph-Convolutional-Networks" class="headerlink" title="Simple and Deep Graph Convolutional Networks"></a>Simple and Deep Graph Convolutional Networks</h2><p>Use two simple techniques to make GNN deep</p>
<ul>
<li><p>Partially aggregate the input feature $H^0$, instead only aggregating previous layers features from its neighborhood</p>
</li>
<li><p>Adding a partial skip connection part</p>
</li>
<li><p><img src="/figures/image-20210311110145347.png" alt="image-20210311110145347"></p>
</li>
</ul>
<h2 id="PAIRNORM-TACKLING-OVERSMOOTHING-IN-GNNS"><a href="#PAIRNORM-TACKLING-OVERSMOOTHING-IN-GNNS" class="headerlink" title="PAIRNORM: TACKLING OVERSMOOTHING IN GNNS"></a>PAIRNORM: TACKLING OVERSMOOTHING IN GNNS</h2><p>Another paper to handle with oversoothing issue in GNNs, i.e., cannot generalize to deep network.</p>
<p><img src="/figures/image-20210311114447474.png" alt="image-20210311114447474"></p>
<p>Here, n is the number of nodes.</p>
<p>The normalization is simply used for the output of each layer</p>
<h2 id="Simplifying-Graph-Convolutional-Networks"><a href="#Simplifying-Graph-Convolutional-Networks" class="headerlink" title="Simplifying Graph Convolutional Networks"></a>Simplifying Graph Convolutional Networks</h2><p>Non-linear 在很多任务中没什么用，GNN可以直接用一个很简单的linear model来表示：</p>
<p>$Y &#x3D; softmax(S^KXW)$, where $S &#x3D; normalized \ A$</p>
<h1 id="理论层面"><a href="#理论层面" class="headerlink" title="理论层面"></a>理论层面</h1><h2 id="GIN"><a href="#GIN" class="headerlink" title="GIN"></a>GIN</h2><p>这个算是个人觉得最有意思的一篇了，大概就是说在座各位基于这种聚合的都是垃圾，最多也只能和从前的WL Test一样。<a href="https://wadmes.github.io/2019/09/14/GNN-GIN-GMN-study/">https://wadmes.github.io/2019/09/14/GNN-GIN-GMN-study/</a></p>
<h2 id="Weisfeiler-and-Leman-Go-Neural-Higher-order-Graph-Neural-Networks"><a href="#Weisfeiler-and-Leman-Go-Neural-Higher-order-Graph-Neural-Networks" class="headerlink" title="Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks"></a>Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks</h2><p>A very good paper that proves a similar conclusion with GIN. (the difference is that they use linear transformation instead of MLP, and finally claim that double the layers (which becomes MLP actually) can have the same performance with WL test)</p>
<p>And then propose a k-GNN based on k-dimensional WL test. Basically, the “supernodes” is all k tuples of the graph.</p>
<h2 id="THE-LOGICAL-EXPRESSIVENESS-OF-GRAPH-NEURAL-NETWORKS"><a href="#THE-LOGICAL-EXPRESSIVENESS-OF-GRAPH-NEURAL-NETWORKS" class="headerlink" title="THE LOGICAL EXPRESSIVENESS OF GRAPH NEURAL NETWORKS"></a>THE LOGICAL EXPRESSIVENESS OF GRAPH NEURAL NETWORKS</h2><p>这篇（ICLR2020）大概就是接着上一篇GIN（ICLR2019）说，诶，确实以前的聚合（自己的+邻居的）都是垃圾，但我这个不一样了，对于每个点还有了个全局（readout）信息。</p>
<p>首先先从一个最简单的给点二分类的问题说起：如果要判断一个点是不是isolated node。我们是不是就没法正确分类了？因为true的点肯定没法传输信息。这个例子实在是妙啊。。</p>
<p>那么这个全局信息是什么呢？就是所有node feature的sum啦。。（ps。。头皮发麻）</p>
<h2 id="WHAT-GRAPH-NEURAL-NETWORKS-CANNOT-LEARN-DEPTH-VS-WIDTH"><a href="#WHAT-GRAPH-NEURAL-NETWORKS-CANNOT-LEARN-DEPTH-VS-WIDTH" class="headerlink" title="WHAT GRAPH NEURAL NETWORKS CANNOT LEARN: DEPTH VS WIDTH"></a>WHAT GRAPH NEURAL NETWORKS CANNOT LEARN: DEPTH VS WIDTH</h2><p>这篇文章的作者。。emm。。怎么说呢，一看就不是国人同时又是为计算机基础知识特别好的大神。</p>
<p>文章的证明需要比较强的计算机背景，不过结论很简洁易懂：</p>
<blockquote>
<p>该研究证明，如果我们想让 GNN 为常见的图问题（如环检测、直径估计、顶点覆盖等）提供解决方案，则节点嵌入的维度（即网络宽度 w）与层数（即网络深度 d）的乘积应与图大小 n 成正比，即 dw &#x3D; O(n)。</p>
</blockquote>
<h2 id="Approximation-Ratios-of-Graph-Neural-Networks-for-Combinatorial-Problems"><a href="#Approximation-Ratios-of-Graph-Neural-Networks-for-Combinatorial-Problems" class="headerlink" title="Approximation Ratios of Graph Neural Networks for Combinatorial Problems"></a>Approximation Ratios of Graph Neural Networks for Combinatorial Problems</h2><p>这篇将GNN和distributed local algorithms 结合了起来，先证明了GNN和distributed local algorithms 是等价的，然后利用以前work对distributed local algorithms的研究得出的结论直接给出了GNN的一些结论。</p>
<p>大概就是现在两种GNN， MB-GNN 和 SB-GNN都比不上 VVC-GNN，定义分别是：</p>
<p><img src="/figures/image-20200819215408321.png" alt="image-20200819215408321"></p>
<p><img src="/figures/image-20200819215427294.png" alt="image-20200819215427294"></p>
<p><img src="/figures/image-20200819215438565.png"></p>
<p>因此，提出了一个VVC-GNN。大概意思就是给别一个边的两个出口都assign一个port，使得所有点给它邻点的信息完全不一样。</p>
<p>最后实验就是用这个model + reinforcement learning 证明了 这个model可以解决很简单的组合优化问题，但是MB，SB都不可以。</p>
<p>在我看来，有个点是没解决的：</p>
<ul>
<li>这种方法注定导致不能迁移到其他graph（相当于给每个edge的port一个人为的index）</li>
<li>这个方法训练时间需要很久，但同时不能用到其他graph。。也太扯了吧。</li>
</ul>
<p>关于distributed local algorithms的定义，请参考 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1205.2051.pdf">https://arxiv.org/pdf/1205.2051.pdf</a></p>
<h2 id="Distance-Encoding-–-Design-Provably-More-Powerful-Graph-Neural-Networks-for-Structural-Representation-Learning"><a href="#Distance-Encoding-–-Design-Provably-More-Powerful-Graph-Neural-Networks-for-Structural-Representation-Learning" class="headerlink" title="Distance Encoding – Design Provably More Powerful Graph Neural Networks for Structural Representation Learning"></a>Distance Encoding – Design Provably More Powerful Graph Neural Networks for Structural Representation Learning</h2><p>添加了一个distance encoding to encode certain distance from S to a node u， 其中S是图中的一部分structure，想学的target structure feature就是S的feature，若S为全图，则为全图的feature(graph embedding). </p>
<p>这里的distance encoding 有比较复杂的formal形式，但是实验里面用的其实就是最简单的两点之间最短距离。</p>
<h2 id="Design-Space-for-Graph-Neural-Networks"><a href="#Design-Space-for-Graph-Neural-Networks" class="headerlink" title="Design Space for Graph Neural Networks"></a>Design Space for Graph Neural Networks</h2><p><strong>Motivation:</strong></p>
<ul>
<li>Surging new GNN tasks, with different requirements</li>
<li>Large design space of GNNs</li>
</ul>
<p><strong>Design space:</strong></p>
<ul>
<li>BN; Number of Pre-process layer (MLP); Number of Message Passing Layers; Sum&#x2F;Mean&#x2F; and son on</li>
</ul>
<p><strong>Task space:</strong></p>
<ul>
<li>Synthetic tasks: node features&#x2F; labels&#x2F; node&#x2F;graph classification </li>
<li>Real-world tasks:  6 node classification benchmarks from [26, 28], and 6 graph classification tasks from [14].</li>
</ul>
<p><strong>GraphGym</strong></p>
<ul>
<li>Modularized GNN implementation</li>
<li>Standardized GNN evaluation.</li>
<li>Reproducible and scalable experiment management</li>
</ul>
<h3 id="Results"><a href="#Results" class="headerlink" title="Results:"></a><strong>Results:</strong></h3><ul>
<li><strong>BN</strong> good!</li>
<li><strong>No Dropout</strong> good!</li>
<li><strong>PRELU</strong> good!</li>
<li><strong>SUM</strong> good!</li>
<li><strong>Adam</strong> good (compared to sgd)</li>
<li><strong>400 epoch</strong> good than 100,200</li>
</ul>
<p>However, besides these “common-sense” conclusions, <strong>desirable design choices for Aggregation, Message passing layers, layer connectivity and post-processing layers drastically vary across tasks</strong></p>
<p><strong>Tasks can be roughly clustered into two groups:</strong></p>
<ul>
<li>(1) node classification over real-world graphs; with <strong>rich node features</strong>; GNN designs that can better propagate <strong>feature information</strong> are preferred; </li>
<li>(2) node classification over synthetic graphs and all graph classification tasks; require <strong>graph structural information</strong></li>
</ul>
<p>How to determine the “best” design for a new task?</p>
<ul>
<li>using $M&#x3D;12$ echor models to test the task, </li>
<li>find the most similar task based on the rankings of the echor models. </li>
<li>use the best design of the most similar task as the “best” design</li>
</ul>
<h2 id="Identity-aware-Graph-Neural-Networks"><a href="#Identity-aware-Graph-Neural-Networks" class="headerlink" title="Identity-aware Graph Neural Networks"></a>Identity-aware Graph Neural Networks</h2><h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><ul>
<li>MP GNN cannot distinguish nodes with the same computational graph.</li>
<li>Although  task-specific feature augmentation;  is not generic and hamper the inductive power </li>
<li>Previous works  task specific; and not based on MP GNN-&gt;not efficient</li>
</ul>
<p><img src="/figures/image-20210306233434885.png" alt="image-20210306233434885"></p>
<h2 id="DropGNN-Random-Dropouts-Increase-the-Expressiveness-of-Graph-Neural-Networks"><a href="#DropGNN-Random-Dropouts-Increase-the-Expressiveness-of-Graph-Neural-Networks" class="headerlink" title="DropGNN: Random Dropouts Increase the Expressiveness of Graph Neural Networks"></a>DropGNN: Random Dropouts Increase the Expressiveness of Graph Neural Networks</h2><p>非常漂亮的文章！</p>
<p>大概就是GNN的upper bound是WL，那么有没有可能突破这个upper bound呢？方法是简单的randomly drop node，这样一个graph 就对应成了 一堆graph 的distribution，那么不同graph 的distribution大概率是不一样的！</p>
<p>这个问题是相同graph的distribution也可能不一样，除非randomly drop的次数足够多，就像投硬币一样。文章里面还给了solid proof about the probability of the distribution close to the real likelihood.</p>
<p>将statistics 里面的一些东西运用到graph里面来，感觉很有潜力啊！</p>
<h1 id="Some-other-interesting-papers"><a href="#Some-other-interesting-papers" class="headerlink" title="Some other interesting papers"></a>Some other interesting papers</h1><h2 id="NEURAL-SUBGRAPH-MATCHING"><a href="#NEURAL-SUBGRAPH-MATCHING" class="headerlink" title="NEURAL SUBGRAPH MATCHING"></a>NEURAL SUBGRAPH MATCHING</h2><p>Done by Stanford Group. The problem is to determine the presence of a given query graph in a large target graph.The key insight that makes NeuroMatch work is to define <strong>an embedding space where subgraph relations are preserved</strong>. That is, : If $G_v$ (k-hop neighborhood of node v) is a subgraph of $G_u$, then node v should be embedded to the lower-left of u. Such relationship is preserved in the embedding space by an elegantly-designed loss function:</p>
<p><img src="/figures/image-20210306233700395.png" alt="image-20210306233700395"></p>
<h2 id="Beyond-Homophily-in-Graph-Neural-Networks-Current-Limitations-and-Effective-Designs"><a href="#Beyond-Homophily-in-Graph-Neural-Networks-Current-Limitations-and-Effective-Designs" class="headerlink" title="Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs"></a>Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs</h2><p>This paper discusses GNNs in graphs where connected nodes may have <em>different</em> class labels and <em>dissimilar</em> features. </p>
<p>Three techniques are used:</p>
<ol>
<li><strong>concatenate</strong> aggreated features insteaed of sum or mean them</li>
<li>Higher-order Neighborhoods, concatenate two-order neighborhood</li>
<li>concatenate (at the final layer) all learned ego-representations at previous layers</li>
</ol>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>写完后，忽然发现了一个也可以算巧合的规律吧？所有方法层面的work基本都是国人lead，但是理论层面的work却寥寥无几。这算不算是一种悲哀呢？方法层面的东西固然重要、效果好，容易发paper，但是理论层面的才是有可能真正推动时代进步的那个钥匙，不过似乎大家都对这种“不好发paper”、“没有确定性”、“难入门”的东西有一种共识性的排斥，算是一种悲哀吧！</p>
<p>其实自己何尝不是这样呢。做了五六个work，除了openmpl，其他的基本都是比较讨巧，迎着市场需求（学术圈热点）做的东西。这是这个时代的无奈，也是我个人的无奈吧，其实也是蛮想做一个沉下心学习研究一两年然后真正contribute to the development of CS的东西，可是现在还只是一个再过几个月要靠publication去砸PHD commitee脸的小小mphil；就算phd了也只是一个担心qualification、担心graduation的PHD student&#x2F;candidate；就算当教授了也需要paper去争tenure啊；就算当了professor，也得对学生负责，在他没有成果前不可能让他做一些我自己都无法保证的东西吧？好像真正可以肆无忌惮做这种work的时间段只有achievement差不多时候的PHD year4&#x2F;5了？</p>
<p>扯的有点多，说回GCN吧。总的看来，其实各种technique&#x2F;theory还是在发展中的，不过里面确实还有很多可以发掘的东西，而且从功利化发paper的角度，不仅仅是Common GCN, 很多子分支，譬如point cloud，譬如heteogeneous graph（参考[<a href="https://wadmes.github.io/2019/12/17/heterogenous%20network/]">https://wadmes.github.io/2019/12/17/heterogenous%20network/]</a>(<a href="https://wadmes.github.io/2019/12/17/heterogenous">https://wadmes.github.io/2019/12/17/heterogenous</a> network&#x2F;)） 这些子分支都是水paper的好方向哪。。</p>
<p>另外就是虽然所有paper的conclusion或者method看起来很简单：这不是本科生都能想到的吗？但是里面的story writing绝对是我得好好研究的：怎么将一个简单的solution包装的很elegant，它解决什么问题的？有什么理论去支撑的？实验怎么设置？这里面都是学问啦。总之，虽然novelty不够，但是发现了这些work的一些共同点：</p>
<ul>
<li>大部分都有看起来牛逼哄哄的theorem&#x2F;proof（对不起因为大部分theorem我没有仔细看，所以只能暂时说看起来。。。）</li>
<li>results部分不会特别出彩，但肯定不是完全比不上别人。1% improvement 🐶，当然如果是专为解决特定问题的，譬如logical问题的那位，就是可以完爆了。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://wadmes.github.io/2020/06/17/How-to-use-grammarly-to-check-your-paper/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/liwei3.jpg">
      <meta itemprop="name" content="Li Wei">
      <meta itemprop="description" content="人生注定是一个人的旅行，但就算孤独也要做一直前行的人啊">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NEWAY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/17/How-to-use-grammarly-to-check-your-paper/" class="post-title-link" itemprop="url">How to use grammarly to check your paper</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-06-17 19:12:43 / Modified: 08:17:31" itemprop="dateCreated datePublished" datetime="2020-06-17T19:12:43-04:00">2020-06-17</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/study/" itemprop="url" rel="index"><span itemprop="name">study</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/06/17/How-to-use-grammarly-to-check-your-paper/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/06/17/How-to-use-grammarly-to-check-your-paper/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>When we finish a paper draft by latex, we may find it difficult to directly use Grammarly to check the grammar since our paper is a .pdf format.</p>
<p>Here is a simple instruction to use Grammarly for your paper. If you have some other more elegant methods, feel free to leave a comment here.  :)</p>
<p>Here are the steps:</p>
<ul>
<li><p>Copy the text in the paper and paste it into VSCode</p>
</li>
<li><p>Replace all “\n” terms into space “ “ terms</p>
</li>
<li><p>Copy the processed text in VSCode and paste it into Grammarly</p>
</li>
<li><p>Find the error and fix it.</p>
<p>![截屏2020-06-17 下午7.19.53](&#x2F;figures&#x2F;截屏2020-06-17 下午7.19.53.png)</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://wadmes.github.io/2020/06/01/PyTorch-Study/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/liwei3.jpg">
      <meta itemprop="name" content="Li Wei">
      <meta itemprop="description" content="人生注定是一个人的旅行，但就算孤独也要做一直前行的人啊">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NEWAY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/01/PyTorch-Study/" class="post-title-link" itemprop="url">ICCAD Proj 总结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-06-01 14:33:06 / Modified: 05:02:31" itemprop="dateCreated datePublished" datetime="2020-06-01T14:33:06-04:00">2020-06-01</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/study/" itemprop="url" rel="index"><span itemprop="name">study</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/06/01/PyTorch-Study/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/06/01/PyTorch-Study/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>离ICCAD还有三星期的时候和老板说想放弃投ICCAD，最后在他的“威逼利诱”下，再加之自己的年轻气盛还是答应了并全力以赴的完成了。想想也是蛮了不起的，不过最后一两个星期实在是太累了点，希望以后还是少点这么肝的时候吧。</p>
<p>这大概一个月，一边做proj一边就有新的感触，每有一个感触，都会自己先记一笔，然后不知不觉的备忘录上就塞满了感触。。。现在一次性都记下来当作以后的吸取教训吧。</p>
<h2 id="Idea-amp-Paper-Review"><a href="#Idea-amp-Paper-Review" class="headerlink" title="Idea &amp; Paper Review"></a>Idea &amp; Paper Review</h2><p>前面两个proj 都分成了c++ 和python&#x2F;pytorch两个板块，因为比较尊重本科生的意见，所以都让他们先选负责的板块（所以都是选的python）。但是有个严重问题：pytorch部分往往和整个proj的idea相关，所以让本科生看paper 找idea实在是好刚没用在刀刃上。因此 两个proj都耽误了比较长的时间。好在自己看paper 总结idea的水平还是比较高了，后面都很快的调整好了方向。</p>
<p>以后在我看来本科生的帮助应该是：</p>
<ul>
<li>跑实验这种大家都需要时间成本，而且学习成本较低的work</li>
<li>画图，implementation就取决于本科生的学习能力和是否有过类似经验了。倘若我和ta都没学过，那让ta来学一下画图也可以（学习成本一个人花费就可以了）</li>
<li>整个idea方向，除非是比较厉害的本科生（这么看我当年其实还是蛮厉害的，在南科大work都是我来看paper想idea），否则应该是我来看paper 总结，想idea，同时简单的传达意思给ta。毕竟确实我看paper的经验，水平肯定高过大部分本科生的。</li>
</ul>
<p>最后再吐槽下吧，好羡慕南科大有那么多本科生帮忙，然后本科生也有各种1&#x2F;2&#x2F;3作paper，实在是双赢。CU的本科教育就花在了倾庄、人文教育上了（当然有research，但是比起内地学校有组织的research还是差远了）。</p>
<h2 id="Coding-style"><a href="#Coding-style" class="headerlink" title="Coding style"></a>Coding style</h2><p>这是看了DGCNN的mit学长的code发出的感慨。感觉任何语言，尤其python，必须要有一套自己习惯的coding style，包括但不限于：</p>
<ul>
<li>argments</li>
<li>i&#x2F;o</li>
<li>error exception handling</li>
<li>model architecture</li>
</ul>
<p>这样的话，自己implementation的时候会方便很多，同时本科小朋友帮忙跑实验也会简单很多（改参数就可以）。哦对了，还有一个要习惯用git。。</p>
<h2 id="Torch-Tensor-Operation"><a href="#Torch-Tensor-Operation" class="headerlink" title="Torch Tensor Operation"></a>Torch Tensor Operation</h2><p>这算是implementation时候的一个点吧。之前习惯了for loop，这次用多了pytorch tensor后发现实在是太爽了。不仅是速度提升（1000x），整个code 也elegant很多。说下从for loop 转成tensor operation的大概idea吧：</p>
<ul>
<li>如果index 不影响operation的话，可以直接用tensor[:]操作</li>
<li>如果影响就需要 生成一个index tensor <ul>
<li>灵活利用torch gather（有一串index 和一个index对应的value， 想通过index取出所有对应value）</li>
<li>利用torch where 来代替 if else</li>
</ul>
</li>
</ul>
<p>晒一下自己生成kbbox（对于每个点，return k个最近的且两点bbox间没有第三个点的所有neighbors）的elegant code吧（对比for loop):</p>
<p>For loop version:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> size <span class="keyword">in</span> <span class="built_in">range</span>(SIZE_OF_NET):</span><br><span class="line">    num_of_sample = <span class="built_in">int</span>(size)</span><br><span class="line">    data = train_data[size].cpu()</span><br><span class="line">    <span class="comment"># data = train_data[size]</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">len</span>(data) == <span class="number">0</span>):</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    index = torch.zeros([data.size(<span class="number">0</span>),data.size(<span class="number">1</span>),num_of_sample]) <span class="comment">#B,N,K</span></span><br><span class="line">    <span class="keyword">for</span> N <span class="keyword">in</span> <span class="built_in">range</span>(data.size(<span class="number">1</span>)):</span><br><span class="line">        <span class="comment">#initialize all value as current node index N</span></span><br><span class="line">        index[:,N,:] = N</span><br><span class="line">    <span class="comment">#for each batch B</span></span><br><span class="line">    max_sample = <span class="number">0</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;PROCESS &quot;</span>,size)</span><br><span class="line">    <span class="keyword">for</span> B <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)): </span><br><span class="line">        <span class="comment">#for each node N</span></span><br><span class="line">        <span class="keyword">if</span>(B % <span class="number">1000</span> == <span class="number">0</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;PROCESS &quot;</span>,size,B)</span><br><span class="line">        <span class="keyword">for</span> N <span class="keyword">in</span> <span class="built_in">range</span>(data.size(<span class="number">1</span>)):</span><br><span class="line">            sample = <span class="number">0</span></span><br><span class="line">            <span class="comment">#We then check each point Q: whether the bounding box between Q and K has no other points, if yes, we add Q in index[B,N,:]</span></span><br><span class="line">            <span class="keyword">for</span> Q <span class="keyword">in</span> <span class="built_in">range</span>(data.size(<span class="number">1</span>)):</span><br><span class="line">                <span class="keyword">if</span>(Q == N):</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="comment">#Coordinate of Q related to N</span></span><br><span class="line">                C_QN = data[B,Q,:] - data[B,N,:]</span><br><span class="line">                is_index = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">for</span> J <span class="keyword">in</span> <span class="built_in">range</span>(data.size(<span class="number">1</span>)):</span><br><span class="line">                    <span class="keyword">if</span>(J == Q <span class="keyword">or</span> J == N):</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line">                    C_JN = data[B,J,:] - data[B,N,:]</span><br><span class="line">                    <span class="keyword">if</span> ((C_JN*C_QN) &gt; (C_JN * C_JN)).<span class="built_in">min</span>():</span><br><span class="line">                        <span class="comment"># print(&quot;Q cannot be index of N due to J&quot;,C_QN,C_JN)</span></span><br><span class="line">                        is_index = <span class="literal">False</span></span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">if</span>(is_index):</span><br><span class="line">                    sample += <span class="number">1</span></span><br><span class="line">                    index[B,N,sample] = Q</span><br><span class="line">            <span class="keyword">if</span>(sample &gt; max_sample):</span><br><span class="line">                max_sample = sample</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;PROCESS &quot;</span>,size, <span class="string">&quot;max_sample: &quot;</span>,max_sample)</span><br><span class="line">    torch.save(index[:,:,:max_sample+<span class="number">1</span>],<span class="string">&quot;../../data/tree/&quot;</span>+<span class="built_in">str</span>(size))</span><br></pre></td></tr></table></figure>

<p>Tensor operation version:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#data : raw distance data (B,N,2)</span></span><br><span class="line">data = tensor</span><br><span class="line"><span class="keyword">if</span>(<span class="built_in">len</span>(data) == <span class="number">0</span>):</span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line"><span class="comment"># print(tensor.size())</span></span><br><span class="line">B,N,_ = data.size()</span><br><span class="line"><span class="comment"># data = train_data[size]</span></span><br><span class="line"><span class="comment"># print(tensor[0])</span></span><br><span class="line"><span class="comment">#inner : (B,N,2) * (B,2,N) = (B,N,N )</span></span><br><span class="line">inner = -<span class="number">2</span> * torch.matmul(data,data.transpose(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">xx = torch.<span class="built_in">sum</span>(data ** <span class="number">2</span>, dim=<span class="number">2</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#pairwise_distance: relative distance between N1 &amp; N2 (B,N1,N2) </span></span><br><span class="line">pairwise_distance = -xx - inner - xx.transpose(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># print(&quot;pairwise_distance&quot;,pairwise_distance[0])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># BNN2 = data.view(B,N,1,2).repeat(1,1,N,1)</span></span><br><span class="line"><span class="comment"># BQQ2 = data.view(B,1,N,2).repeat(1,N,1,1)</span></span><br><span class="line"><span class="comment"># print(&quot;BNN2&quot;,BNN2[0][0])</span></span><br><span class="line"><span class="comment"># print(&quot;BQQ2&quot;,BQQ2[0][0])</span></span><br><span class="line"><span class="comment">#BNQ2: value in (b,n,q) is the relative coordinates between node n and node q at b_th batch.</span></span><br><span class="line"><span class="comment"># BNQ2 = BNN2 - BQQ2</span></span><br><span class="line">BNQ2 = data.view(B,N,<span class="number">1</span>,<span class="number">2</span>) - data.view(B,<span class="number">1</span>,N,<span class="number">2</span>)</span><br><span class="line"><span class="comment"># print(&quot;BNQ2&quot;,BNQ2[0][0])</span></span><br><span class="line"><span class="comment">#CQN: value in (b,n,q,j) is the relative coordinates between node n and node q at b_th batch.</span></span><br><span class="line"><span class="comment">#CJN: value in (b,n,q,j) is the relative coordinates between node n and node j at b_th batch.</span></span><br><span class="line"><span class="comment">#UPDATE: The view step here is not neccesary since pytorch will automatically scale the tensor shape</span></span><br><span class="line">CQN = BNQ2.view(B,N,N,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">CJN = BNQ2.view(B,N,<span class="number">1</span>,N,<span class="number">2</span>)</span><br><span class="line"><span class="comment"># print(&quot;CQN&quot;,CQN[0][0])</span></span><br><span class="line"><span class="comment"># print(&quot;CJN&quot;,CJN[0][0])</span></span><br><span class="line"><span class="comment">#BNQJ: value in (b,n,q,j) indicates that when n is the centroid, whether j is in the bounding box of q and n (and such makes q not connected to j)</span></span><br><span class="line"><span class="comment">#True means the j influences q</span></span><br><span class="line">BNQJ = (CQN*CJN &gt; CJN*CJN).<span class="built_in">min</span>(-<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># print(&quot;BNQJ&quot;,BNQJ[0][0])</span></span><br><span class="line"><span class="comment">#BNQJ: value in (b,n,q) indicates that when n is the centroid, whether q cannot connect to n</span></span><br><span class="line"><span class="comment">#True mans q cannot conncet n</span></span><br><span class="line">BNQ = BNQJ.<span class="built_in">max</span>(-<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># print(&quot;BNQ&quot;,BNQ[0])</span></span><br><span class="line"><span class="comment">#For those q who cannot connect to n (which is exactly True in BNQ), we assign a large distance value(10000)</span></span><br><span class="line">_,index = ((pairwise_distance - (BNQ.long() * <span class="number">10000</span>))).topk(k=<span class="number">4</span>,dim = <span class="number">2</span>)</span><br><span class="line"><span class="comment"># print(&quot;index&quot;,index[0])</span></span><br><span class="line"><span class="comment"># exit()</span></span><br><span class="line">torch.save(index,<span class="string">&quot;../../data/tree/kbbox_&quot;</span>+<span class="built_in">str</span>(i)+<span class="string">&#x27;_&#x27;</span>+<span class="built_in">str</span>(j))</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这个work应该是自己这么多work里面最满意的一个了？虽然比较仓促，但是整个story是连贯的，对应方法也不是和一般dl-based work一样讲究一个玄学，基本都是有规律有原因能解释的。最后的结果也是比较满意（最后两三天的时候加上了FLUTE的结果实在是不太行，临时把FLUTE remove了，最后一天才算出结果。。也是没谁了）</p>
<p>这个要是结果ICCAD没中可就滑稽了。投paper这个东西就真的可以叫做玄学了。ß</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://wadmes.github.io/2020/05/20/ICCAD%E5%89%8D%E7%9A%84%E5%81%B7%E6%87%92%E6%9C%88%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/liwei3.jpg">
      <meta itemprop="name" content="Li Wei">
      <meta itemprop="description" content="人生注定是一个人的旅行，但就算孤独也要做一直前行的人啊">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NEWAY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/20/ICCAD%E5%89%8D%E7%9A%84%E5%81%B7%E6%87%92%E6%9C%88%E8%AE%B0/" class="post-title-link" itemprop="url">ICCAD前的偷懒月记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-20 00:04:08" itemprop="dateCreated datePublished" datetime="2020-05-20T00:04:08-04:00">2020-05-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-03 11:58:28" itemprop="dateModified" datetime="2020-06-03T11:58:28-04:00">2020-06-03</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/life/" itemprop="url" rel="index"><span itemprop="name">life</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/05/20/ICCAD%E5%89%8D%E7%9A%84%E5%81%B7%E6%87%92%E6%9C%88%E8%AE%B0/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/05/20/ICCAD%E5%89%8D%E7%9A%84%E5%81%B7%E6%87%92%E6%9C%88%E8%AE%B0/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>写这篇文章的时候是5.20，也算是个特殊的日子。</p>
<p>本来一直想着等ICCAD搞完再写点东西。。但好多东西都是推到之后做，等ICCAD搞完想想申请PHD的事。。等ICCAD搞完学一下你不要担心的吉他。。。等ICCAD搞完想想感情的事。。加之这连续几天的失眠，感觉不写点东西，对自己赶DDL会有反作用了。</p>
<p>所以还是把五月份这段时间的（部分）想法先记一下吧。</p>
<h2 id="厉害的本科生-高山流水"><a href="#厉害的本科生-高山流水" class="headerlink" title="厉害的本科生 高山流水"></a>厉害的本科生 高山流水</h2><p>我是个不太喜欢吐槽的人……心里经常会告诉自己要做一个不怨天不尤人的好孩子……</p>
<p>但对不起今天实在是想吐槽一下了……</p>
<p>我记得我本科时候身边内地生同学都是大佬，没想过有些本科生水平可以这么糟糕</p>
<p>从linux怎么cp 到什么是make 到甩我一个c文件问我能不能帮debug，</p>
<p>真没想到给港中文本科生解决问题有教我爷爷用微信那感觉了，但问题是你们是港中文cse的本科生啊[捂脸] 我把command给你 你还少打了一串arguments，然后又问我为啥error；我告诉你scp 实在不会的话下个mobaxterm你嫌两个都太麻烦；……</p>
<p>算了 不说了，不过普遍来看内地生和部分local还是蛮厉害的，和这些同学沟通起来还是蛮舒服的，很多时候意会一下双方就明白意思了，有点高山流水的爽快感。</p>
<p>anyway 每天回复50+邮件的日子总算过去了……</p>
<p>（以上是之前发的朋友圈，觉得有损母校声誉于是删了，放这算一个备份吧（虽然感觉声誉本身就损的差不多了哈哈））</p>
<h2 id="家乡的雨香"><a href="#家乡的雨香" class="headerlink" title="家乡的雨香"></a>家乡的雨香</h2><p>前段时间下了一次很突然的雨，突然到一瞬间就从白天到了黑夜。</p>
<p>之前对于雨没有什么特别的感觉，直到这次刚好写代码写的脑子晕所以打开门去阳台上休息会。打开门的一瞬间，那熟悉的雨的味道就回来了：呵，这不是家乡的雨香么！或者说，所有地方的雨香其实都是这样？但是不需要考虑这种理性逻辑因素，这样的雨香，我上次闻到，还是少年时代在家乡和小伙伴雨中嬉戏时的味道，这就够了。</p>
<p>然后心里合计着，好像真的很久没回家了。心里想家的想法一点点的膨胀，膨胀到看着远处的李兆基楼：怎么那么像我妈的那栋住院大楼。。🤦‍♂️。</p>
<p>没回家越久，便越睹物思人。偏偏今年的月亮又好几次特别大。每次看着月亮，就会陷入儿时和老辉他们中秋一起烤板栗的回忆，是啊，人生总得有这些浪漫的时刻与重要的人度过，这样才精彩，才能觉得来世上一遭不虚此行哪！</p>
<h2 id="愿为江水-与君重逢"><a href="#愿为江水-与君重逢" class="headerlink" title="愿为江水 与君重逢"></a>愿为江水 与君重逢</h2><p>前段时间偶然在b站刷到了文在寅和卢武铉的故事。</p>
<p>先不论真相如何，至少所描写的故事实在是太对我口味了：两人都是抱着为民请命志向的君子，且都是高山流水的知音。卢武铉功成名就之时，文在寅默默隐退，卢武铉因为自身名誉自杀，文在寅复出，为了完成两人没能成功的理想：打败财阀，将幸福归于人民。卢武铉很喜欢江水这个概念，他认为人民就是江水，只有汇聚到一起，才能成为海洋，拥有惊人的力量。而文在寅的这句“原为江水，与君重逢”字如其意，希望有一天两人能在追求理想的道路上像江水一般，重逢。</p>
<p>就像个人英雄主义在欧美很吃得香一样，这样的家国情怀、士为知己者死的故事实在太对我们儒家文化圈的人口味了，归根到底，我只是一个生在儒家文化圈里的一个崇敬知其不可为而为之的书生而已。从诸葛亮，到于谦，再到隐形守护者里的那些为自己理想追求的人，所有这些有着坚定理想的人，是多么有魅力。</p>
<p>然后想想自己，其实还是很惭愧的。虽然自己有自己个人道路的理想，成为教授；也有对于社会的理想，见证一个真正的共产主义政府的诞生；但是好像没有做过什么为了理想而奋不顾身的选择：好像自己终究只是被生活逼着的芸芸众生，之所以会敬佩喝彩那些人，也只是因为自己做不到，所以将这希望寄托在他们身上？。</p>
<h2 id="master-of-philosophy"><a href="#master-of-philosophy" class="headerlink" title="master of philosophy"></a>master of philosophy</h2><p>可能是我离开了之前那个舒适圈，也可能是这次疫情给自己很多的“思考人生”的时间，自己好像确实有点像一个master of philosophy了。</p>
<p>大概就是，明显的能感觉到以前很多迷茫的东西、或者想不明白的东西，想通了，不害怕了，但想的人也没那么简单（或者说愣头青）了。不过这方面之前几篇月记也说过了，不谈也罢。</p>
<h2 id="看得开-逃避"><a href="#看得开-逃避" class="headerlink" title="看得开 逃避"></a>看得开 逃避</h2><p>大概是18年开始，自己形成了一个比较苏轼的三观：大概就是一蓑烟雨任平生的豁达乐观、对任何东西好像都不是特别想争取，很看得开。不过这是说的好听的话、说得难听就是什么东西都会逃避。我对什么东西都不会抱很强的希望，可能是害怕求而不得的失望，不论是感情还是事业，都是随遇而安就好。</p>
<p>这种心态挺好的，但对应的行为其实并不显得好。就像我之前回忆我颓废的几年大学：得过且过的人生会像温水煮青蛙一样消磨人的意志和思想，当再想去追逐思考一些东西，比如幸福，的时候，人就像那青蛙一样，再也无能为力，只能抱憾终生。（说去题外话，自己很多时候只注意到表面上的收益或者得失，但很多东西是对我们有潜移默化影响而我们自己感觉不到的。譬如觉得一天工作16小时总工作量会最大化，但是花一点时间去外面呼吸新鲜空气 感觉自然的颜色，往往能给我们一种说不出来的畅快。）</p>
<p>所以总的来说就是。豁达的心态不代表什么都无所谓。很多东西，譬如感情、譬如事业，是要花心思去努力争取、维护的，不是摆在那里就能茁壮成长的。wuli小巍啊，要做一个像阿泽一样勇敢去争取的人哪。</p>
<h2 id="家庭-远见-初中升高中"><a href="#家庭-远见-初中升高中" class="headerlink" title="家庭 远见 初中升高中"></a>家庭 远见 初中升高中</h2><p>现在越发的感觉家庭对人成长的影响至关重要。不仅仅是性格上，还有人生抉择上。</p>
<p>倘若家长没有深刻的思想或长远的见识，孩子也不会有很高的远见。除非他在成长路上幸运的有了不一样的人生经历：书+思考，或是贵人指点+思考。否则，大概率孩子也会继承家长的短视。这怨不了家长，家长自己也不会意识到这点。他们中的大多数，都成为了一些冷门专业的学生，成为了大学迷茫随大流的孩子。不禁感慨，阶级跨越是有多难啊！</p>
<p>想起自己初中升高中的时候，其实自己也算是很有天赋的一个人，但是无奈没有系统性的教育，导致雅礼的精英班考试考的一塌糊涂：全都是没学过的奥赛内容，我怎么和别人学过的比？现在还记得最后语文作文知道自己肯定考不上，写了一段心里话：大概是表达自己的自卑，感觉考场里的别的同学都特别厉害，动笔就做，反观自己什么都不知道，完全和自己学的不一样，完全和自己随随便便全校第一的考试不一样。</p>
<p>如果时光能倒流，或者能写信：就像hey kong一样，我好想告诉那个自卑的孩子：你一点都不比别人差，你不会只是因为没人教你，没考上就没考上，未来你的高中照样很耀眼，你的人生也是走上了一条还算幸运的道路呀。</p>
<p>真的只能用幸运这个词。从高中见识到他山之高后的努力，到大学选了计算机专业，再到选择了mphi这条路，所有这些选择都不是什么有着父母、高人指导的远见之举，纯粹只是偶然、爱好、随波逐流，但是万幸，最后的结果不算差，虽然前方的路不像有些人那样到处都是灯光如昼，虽然自己前行的路需要黑暗中自己摸索，但是好像走的也算比较远了。</p>
<p>所以经常会想以后有了孩子会怎么样，会去发现他的各种爱好，倘若喜欢，就多去学点，万一在哪方面有天赋呢？还会督促他的学习，至少不会让他有那种自卑的瞬间。还会让他有个依靠，让他清清楚楚的明白爸妈会是他最后退无可退时候的退出。</p>
<p>哦不，是她。我想要女儿，哼。</p>
<h2 id="小车结婚"><a href="#小车结婚" class="headerlink" title="小车结婚"></a>小车结婚</h2><p>小车结婚了，收到消息的时候先是一惊，然后就想起来余丝很早就和我提过这事。</p>
<p>然后就是长久长久长久长久 一直到现在还陷在里面的思绪。想到那时候还和她计划着一起去，想到不出意外明年结婚的就是我们了，然后又想到噢好像已经分手半年多了，然后梦到她嫁给别人，我不知道躲在多少个角落里哭了多少次。</p>
<p>好像自己还是那么想她。没有她我就感觉要死掉了的那种想。之前有过感慨要是自己不是和她谈对象该多好：两个单亲家庭的孩子互相喜欢真是人间最大的悲喜剧。但没有这么多要是，就算有如果、有平行时空，我唯一知道的是，我在的这个时空，这个我学了计算机以后可能要去读PHD的时空，不管别的平行时空怎么样，不管我们是不是合不合适，她就是我唯一的意难平、就是唯一的那个分手后会让我听着李宗盛哭一垃圾桶纸的人、唯一那个陪了我度过整个青春的人、唯一这么久后会因为同学的结婚又整晚整晚睡不着的人。</p>
<p>其实也不是没有去试着喜欢别的女孩子，但没有什么人什么事能让随遇而安的我有一点点的波澜。好像有比她漂亮点、高一点、学历好点，但这种纯粹的对比只是成人世界中的，在真正的感情里是没有这些成年人基于表面价值的价值判断的：当你拿着秤砣去衡量一份感情，这感情就掺杂了你以为的表面价值，最终只会失去原本的、弥足珍贵、许多人求之不得的感情。</p>
<h2 id="分开的原因"><a href="#分开的原因" class="headerlink" title="分开的原因"></a>分开的原因</h2><p>好像说了这么多一直是在说她有多好。或者说对我多重要。</p>
<p>换个话题，说说为什么分开吧。</p>
<p>这段波折的感情史，第一次大的波折应该是那次她离家出走。在那之前，初恋的我还是对恋爱有一些幼稚的、理想国般的幻想的（本来她也是，但不知道什么时候开始变得）。</p>
<p>大概就是说好两个人不能给异性发表情包（哈哈哈我们当年是怎么提出来这种奇葩要求的），结果我那天看到她发了，于是质问她，要求她以后不能发，但被她冷漠的拒绝了。但论这件事放在我现在看，我会更加站她一点，虽然是说好的，但是这个说好的本身也太。。不过当时她那张冷漠绝情的脸真可以说是让我毕生难忘，也直接给了那个还报美好幻想的少男一次感情上的核打击：原来一个人可以变得这么快，前一秒还是少男少女的如胶似漆，下一秒直接绝情的好像不曾爱过你。其实思想，尤其是初恋男女对于感情的思想，是需要时间去成熟的，但那次就好像飞机没有软着陆而直接坠落在机场一样，好像自己对于这段爱情的所有期望都全破灭了，然后就变成随遇而安的状态了。后面和她说过这件事对我的伤害、她也嘟囔了一句对不起（我能感觉到她是真的歉意），但我随遇而安的态度从那之后好像就一直没变。</p>
<p>类似的是，我们的感情里面她也有一次“坠机”般的硬着陆。有次分手后没几天，我去北京开会认识了一个姑娘，然后两个人也聊的很来。我好像就是这样贱（渣），因为习惯了和她在一起时有个依靠，所以她一消失会急于寻找一个替代：听起来有点辩解的意思，但是好像就是如此，我从小就没有一个和睦的家庭，一个可以当作港湾的家庭。对我来说，我这辈子，有过的唯一依靠，就是她。后来她来找我和好，但是我没有和那个姑娘说，只是刚好自己回香港所以也直接对那个姑娘冷淡很多。再然后被她发现了，我能感觉到她是真的真的好难受，就像我那次打碎了对爱情的所有期望一样，她也打碎了她的美好的期望。。。虽然我道歉哄好了她，但是那段时间我做的真的不好，可能是因为自己已经成为随遇而安的性格。我现在很后悔的是，她“坠机”后没能重新让她上一架新飞机，没能告诉她 这个世界上她是除自己之外对我最重要的人，也没能生活上细节上注意一下她微小的情绪：如果当时我就看了1988该多好。</p>
<p>总之经过这两件事，我变得随遇而安，感觉什么都随自然就好，包括感情。她变得对我们的爱情失去信心，再加之我随遇而安的态度，开始越来越失望，越来越不重视感情。</p>
<p>然后就是导火索了，大概就是她和同事出去吃饭，说好晚上10.00-11.00回来，结果12.00还没走，而且一晚上不主动发微信消息。然后我很生气，结果她一副“我错了 然后呢“，一直跟我”据理力争“，真是把我气的不行（我现在想来都好委屈好气，明明是她做错了，而且错的还很厉害，为什么可以这么嚣张 还 想先给我扣一个我也干了的帽子然后来批判我。）不过这个导火索算是偶然中的必然吧？一个随自然的人，加上一个不重视的人，总会出现类似这样的事。</p>
<p>两个人都是彼此青春的见证者，更要命的是因为单亲，还都是彼此最重要最融入人生的那个人，好像就这么错过会太遗憾了。不知道何时才能解除封关，那时候应该会去再加油一下吧。至少要把这些东西告诉她吧。</p>
<p>要做一个像阿泽那样的少年哪。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/15/">15</a><a class="extend next" rel="next" href="/page/6/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Li Wei"
      src="/images/liwei3.jpg">
  <p class="site-author-name" itemprop="name">Li Wei</p>
  <div class="site-description" itemprop="description">人生注定是一个人的旅行，但就算孤独也要做一直前行的人啊</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">143</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/wadmes" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;wadmes" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:werry715@gmail.com" title="E-Mail → mailto:werry715@gmail.com" rel="noopener" target="_blank"><i class="fas fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://music.163.com/#/playlist?id=49000450" title="Music → https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;playlist?id&#x3D;49000450" rel="noopener" target="_blank"><i class="fas fa-music fa-fw"></i>Music</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://steamcommunity.com/id/wadmes/" title="Steam → https:&#x2F;&#x2F;steamcommunity.com&#x2F;id&#x2F;wadmes&#x2F;" rel="noopener" target="_blank"><i class="fab fa-steam fa-fw"></i>Steam</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="link fa-fw"></i>
      Interesting links!
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://wadmes.github.io/2019/12/11/EDA-family-tree/" title="https:&#x2F;&#x2F;wadmes.github.io&#x2F;2019&#x2F;12&#x2F;11&#x2F;EDA-family-tree&#x2F;">EDA family tree</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://wenku.baidu.com/view/f5cdb37aeff9aef8951e0673" title="https:&#x2F;&#x2F;wenku.baidu.com&#x2F;view&#x2F;f5cdb37aeff9aef8951e0673" rel="noopener" target="_blank">小爷当年的高考满分作文</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Li Wei</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='50' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : true,
      appId      : 'NmNqnbed4p8koRJWwGm6SdrW-gzGzoHsz',
      appKey     : 'ECnYjjxnwouXPYlJjrjLJhv9',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
